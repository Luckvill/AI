{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93b4c931",
   "metadata": {},
   "source": [
    "## Ejecutar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2708a11b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from tensorflow.keras import Model\n",
    "from keras.losses import mse\n",
    "from tensorflow.keras.layers import MaxPooling2D, Input, Dense, Lambda, Conv2D, Flatten, Reshape, Conv2DTranspose, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras import preprocessing\n",
    "import time\n",
    "import io\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create the Tensorboard writer\n",
    "tensorboard= tf.summary.create_file_writer(logdir='logs/{}'.format(\"Cars{}\".format(int(time.time()))))\n",
    "\n",
    "# Specify the directory where the images to train the network are located\n",
    "directory=\"\" # Format: \"{directory}\"\n",
    "\n",
    "# Specify the size of the images that the network should generate\n",
    "img_size = 128\n",
    "\n",
    "# Specify the folder where the trained model will be saved\n",
    "trained_models_folder =\"\" # Format: \"{directory}\\ \"\n",
    "\n",
    "# Specify the folder where the images generated by the model will be saved\n",
    "generated_images_folder=\"\" # Format: \"{directory}\\ \"\n",
    "\n",
    "# Specify the batch size\n",
    "batch_size = 70\n",
    "\n",
    "# Specify the dimension of the latent space\n",
    "latent_dim=100\n",
    "\n",
    "# Specify how many images to show for reconstructions\n",
    "num_examples_to_generate = 25\n",
    "\n",
    "# Specify the shape of the input vector\n",
    "input_shape = (128,128,3)\n",
    "\n",
    "# Load the car dataset, normalize, resize and horizontally flip its images\n",
    "def get_loader(img_size):\n",
    "    def augment(img):\n",
    "        return tf.image.random_flip_left_right(img)\n",
    "    def train_preprocessing(x):\n",
    "        x = tf.cast(x, tf.float32)\n",
    "        x = x / 255.0  # normalization\n",
    "        x = augment(x)\n",
    "        return x\n",
    "    dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        directory,\n",
    "        label_mode=None,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        seed=123,\n",
    "        image_size=(img_size, img_size),\n",
    "    )\n",
    "    datasetmapeado = dataset.map(lambda x: train_preprocessing(x))\n",
    "    return datasetmapeado\n",
    "dataset=get_loader(img_size)\n",
    "\n",
    "\n",
    "# Build the encoder\n",
    "def get_encoder():\n",
    "    entradas = Input(shape=(input_shape[0],input_shape[0],3))\n",
    "    x = entradas\n",
    "    # Create variable i to index the layers in the loop\n",
    "    i=0\n",
    "    # Loop to transform the images received by the input method to dimensions (64,64,32), (32,32,64), (16,16,128), (8,8,256), (4,4,512)\n",
    "    for filtro in [32,64,128,256,512]: \n",
    "        x = Conv2D(filtro, kernel_size=(3,3), strides=1, padding='same',name='Encoder_Conv2D_'+str(i))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = MaxPooling2D()(x)\n",
    "        i=i+1\n",
    "    # \"Flatten\" the output vector from the loop\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(latent_dim*2, activation='relu')(x)\n",
    "    x_media = Dense(latent_dim, activation='relu')(x)\n",
    "    x_var = Dense(latent_dim, activation='relu')(x)\n",
    "    # Define the mean with a Dense layer\n",
    "    media = Dense(latent_dim, name='Mean')(x_media)\n",
    "    # Define the logarithm of the variance with a Dense layer\n",
    "    log_var = Dense(latent_dim, name='Variance')(x_var)\n",
    "    \n",
    "    # Build the Samples function to sample from the approximate normal distribution\n",
    "    def Samples(args):\n",
    "        # Get the mean and log variance vectors\n",
    "        z_media, z_log_var = args\n",
    "        # Create an epsilon vector with mean 0 and standard deviation 1 for reparameterization\n",
    "        epsilon = K.random_normal(shape=(K.shape(z_media)[0], K.shape(z_media)[1]), mean=0., stddev=1.)\n",
    "        # Sample from a standard normal through reparameterization\n",
    "        return z_media + K.exp(0.5 * z_log_var) * epsilon\n",
    "    \n",
    "    # Call the Samples function to generate the samples that will be passed to the decoder\n",
    "    latent = Lambda(Samples, name='Samples')([media, log_var])\n",
    "    # Build the encoder model\n",
    "    encoder = Model(entradas,[latent, media, log_var], name='Encoder')\n",
    "    return encoder\n",
    "\n",
    "# Build the decoder\n",
    "def get_decoder():\n",
    "    entradas = Input(shape=(latent_dim,))\n",
    "    x = entradas\n",
    "    # Resize the input vector to (batch_size,400)\n",
    "    x = Dense(latent_dim*2, activation='relu')(x)\n",
    "    # Resize the received vector to (batch_size,4*4*512)\n",
    "    x = Dense(4*4*512)(x)\n",
    "    # Resize the received vector to (batch_size,4,4,512)\n",
    "    x = Reshape((4, 4, 512))(x)\n",
    "    # Create variable i to index the layers in the loop\n",
    "    i=0\n",
    "    # Loop to transform the images received by the input method to dimensions (8,8,512), (16,16,256), (32,32,128), (64,64,64), (128,128,32)\n",
    "    for filtro in [512, 256, 128, 64, 32]:\n",
    "        x = Conv2DTranspose(filtro, 3, strides=2, padding='same',name='Decoder_Conv2DTranspose_'+str(i))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        i=i+1\n",
    "    # Transform the vector received from the loop to dimensions (128,128,3)\n",
    "    salidas = Conv2D(3, kernel_size=1, strides=1, padding='same', activation='sigmoid')(x)\n",
    "    # Build the decoder model\n",
    "    decoder = Model(entradas, salidas, name='Decoder')\n",
    "    return decoder\n",
    "\n",
    "# Build the VAE\n",
    "def get_vae(codificador, decodificador, optimizador):\n",
    "    entradas = Input(shape=(input_shape[0],input_shape[0],3))\n",
    "    # Extract samples from the approximate distribution from the encoder\n",
    "    z = codificador(entradas)[0]\n",
    "    # Get the mean of the distribution\n",
    "    media = codificador(entradas)[1]\n",
    "    # Get the variance of the distribution\n",
    "    log_var = codificador(entradas)[2]\n",
    "    # Get the output vector from the decoder that receives the z encodings as input\n",
    "    salidas = decodificador(z)\n",
    "    # Build the VAE model\n",
    "    vae = Model(entradas, salidas, name='VAE')\n",
    "    # Calculate the MSE reconstruction loss\n",
    "    mse_loss = mse(K.flatten(entradas), K.flatten(salidas))\n",
    "    # Calculate the KL divergence\n",
    "    kl_loss = 1 + log_var - K.square(media) - K.exp(log_var)\n",
    "    kl_loss = K.sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "    # Calculate the network loss as the sum of KL divergence and reconstruction loss * 10000 (multiplied to give it more relevance)\n",
    "    loss = K.mean(mse_loss*10000 + kl_loss)\n",
    "    # Add the KL divergence, reconstruction loss and network loss to the VAE\n",
    "    vae.add_loss(loss)\n",
    "    vae.add_metric(kl_loss, name='kl_loss')\n",
    "    vae.add_metric(mse_loss, name='mse_loss')\n",
    "    # Compile the VAE with the Adam optimizer\n",
    "    vae.compile(optimizer=optimizador)\n",
    "    return vae\n",
    "\n",
    "# Create the variables that will contain the generator and discriminator models\n",
    "encoder = get_encoder()\n",
    "decoder = get_decoder()\n",
    "# Create the VAE optimizer\n",
    "vae_optimizer=tf.keras.optimizers.Adam(0.0005)\n",
    "vae = get_vae(encoder,decoder,vae_optimizer)\n",
    "\n",
    "# Return the summary of the VAE, encoder and decoder\n",
    "vae.summary()\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "\n",
    "# Return the images in a format that allows storing them in Tensorboard\n",
    "def plot_to_image(figure):\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "# Create a 5x5 grid with the images it receives\n",
    "def image_grid(images):\n",
    "    figure = plt.figure(figsize=(10,10))\n",
    "    for i in range(images.shape[0]):\n",
    "        img = preprocessing.image.array_to_img(images[i])\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(img)\n",
    "\n",
    "# Generate and save the images produced by the generator in a local folder\n",
    "def generate_and_save_images(folder,model, epoch, seed, dim=(5, 5), figsize=(5, 5)):\n",
    "    generated_images = model(seed)\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        img = preprocessing.image.array_to_img((generated_images[i] + 1 / 2))\n",
    "        plt.imshow(img)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(folder + 'generated_image_epoch_%d.png' % epoch)\n",
    "    plt.close()\n",
    "    return generated_images\n",
    "\n",
    "# Function to calculate the VAE network error\n",
    "def vae_loss(x):\n",
    "    encoded, mean, logvar = encoder(x)\n",
    "    x_logit = decoder(encoded)    \n",
    "    mse_loss = mse(K.flatten(x), K.flatten(x_logit))\n",
    "    kl_loss = 1 + logvar - K.square(mean) - K.exp(logvar)\n",
    "    kl_loss = K.sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "    vae_loss = K.mean(mse_loss*10000 + kl_loss)\n",
    "    return vae_loss,kl_loss,mse_loss\n",
    "\n",
    "# Train the network through train_step\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    # Train the network by passing real images from the dataset\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Calculate the network error\n",
    "        loss,kl_loss,mse_loss = vae_loss(images)\n",
    "     # Update the VAE gradients\n",
    "    gradients = tape.gradient(loss, vae.trainable_variables)\n",
    "    vae_optimizer.apply_gradients(zip(gradients, vae.trainable_variables))\n",
    "    return loss, kl_loss, mse_loss\n",
    "\n",
    "# Extract a set of images from the dataset to observe how reconstructions are performed\n",
    "for image in dataset.take(1):\n",
    "    seed = image[0:num_examples_to_generate, :, :, :]\n",
    "\n",
    "def train(dataset, epochs):\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # Generate images before the network starts training\n",
    "        generate_and_save_images(generated_images_folder,vae, 0, seed)\n",
    "        print('Current training epoch {} (out of a total of {}).'.format(epoch+1, epochs))\n",
    "         # Loop that iterates over the dataset to train the network\n",
    "        for image_batch in tqdm(dataset):\n",
    "            loss, kl_loss, mse_loss=train_step(image_batch)\n",
    "        # Generate and save reconstructions as the network evolves\n",
    "        generated_images=generate_and_save_images(generated_images_folder,vae, epoch, seed)\n",
    "        fig=image_grid(generated_images)\n",
    "        fig2=image_grid(seed)\n",
    "        with tensorboard.as_default():\n",
    "            # Print in Tensorboard the VAE error, KL divergence value, reconstruction loss and images generated by the network\n",
    "            tf.summary.scalar('Loss VAE', loss, step=epoch)\n",
    "            tf.summary.scalar('kl_loss VAE', K.mean(kl_loss), step=epoch)\n",
    "            tf.summary.scalar('mse_loss VAE', K.mean(mse_loss), step=epoch)\n",
    "            tf.summary.image('Generated images', plot_to_image(fig), step=epoch)\n",
    "            tf.summary.image('Real images', plot_to_image(fig2), step=epoch)\n",
    "        # If the current epoch is a multiple of 10 then save the VAE\n",
    "        if epoch % 10 == 0:\n",
    "            vae.save_weights(trained_models_folder + \"VAE_epoch_%d\" % epoch)\n",
    "\n",
    "    # Save the last reconstructions produced by the VAE\n",
    "    generate_and_save_images(generated_images_folder,vae, epoch, seed)\n",
    "\n",
    "# Call the train function to start training\n",
    "train(dataset, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6b086e",
   "metadata": {},
   "source": [
    "## Generar imágenes nuevas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa942630",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Function to create new samples (not reconstructions), from a standard distribution with zero mean and standard deviation 1\n",
    "def vae_generate_images(samples):\n",
    "    reconst_images = decoder.predict(np.random.normal(0,1,size=(samples,200)))\n",
    "    image_grid(reconst_images)\n",
    "\n",
    "# Call the function to generate samples indicating the number of samples to take (if you want to change it, make it compatible with the image_grid function)\n",
    "vae_generate_images(samples=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3e6ea6",
   "metadata": {},
   "source": [
    "## Imprimir la aproximación a la distribución normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa78111",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Take the output vector from the encoder by passing the generated seed to later see how it approximates the normal distribution\n",
    "z_aux, _, _ = encoder.predict(seed)\n",
    "x = np.linspace(-3, 3, 200)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "fig.subplots_adjust(hspace=0.6, wspace=0.4)\n",
    "\n",
    "for i in range(50):\n",
    "    ax = fig.add_subplot(5, 10, i+1)\n",
    "    ax.hist(z_aux[:,i], density=True, bins = 20)\n",
    "    ax.axis('off')\n",
    "    ax.text(0.5, -0.35, str(i), fontsize=10, ha='center', transform=ax.transAxes)\n",
    "    ax.plot(x, norm.pdf(x))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
