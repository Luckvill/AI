{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8d8e10f",
   "metadata": {},
   "source": [
    "## Ejecutar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99b7c09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from inspect import isfunction\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow import einsum\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from tensorflow.keras.models import save_model\n",
    "from keras.losses import mse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import preprocessing, Sequential\n",
    "import time\n",
    "import io\n",
    "from tqdm import tqdm\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "# Tensorboard writer is created\n",
    "tensorboard= tf.summary.create_file_writer(logdir='logs/{}'.format(\"Cars{}\".format(int(time.time()))))\n",
    "\n",
    "# Directory where the images for training the network are located is specified\n",
    "directory=\"\" # Format: \"{directory}\"\n",
    "\n",
    "# Image size that the network should generate is specified\n",
    "img_size = 128\n",
    "\n",
    "# Folder where the trained model will be saved is specified\n",
    "trained_models_folder =\"\" # Format: \"{directory}\\ \"\n",
    "\n",
    "# Folder where the images generated by the model will be saved is specified\n",
    "generated_images_folder=\"\" # Format: \"{directory}\\ \"\n",
    "\n",
    "# Batch size is specified\n",
    "batch_size = 12\n",
    "\n",
    "# Number of groups used in Group Normalization is specified\n",
    "norm_groups = 4\n",
    "\n",
    "# Number of timesteps for the forward and reverse process is set\n",
    "timesteps=1000\n",
    "\n",
    "# Filters to be applied in the network are set\n",
    "filters = [32,64,128,256]\n",
    "\n",
    "# Indicates which levels of the network use attention blocks\n",
    "isAttentionLevel = [False, False, True, True]\n",
    "\n",
    "# Number of residual blocks at each downsampling level (one more for upsampling)\n",
    "nRes_blocks = 2\n",
    "\n",
    "# Loads the car dataset, normalizes and horizontally flips its images\n",
    "def get_loader(image_size):\n",
    "    def augment(img):\n",
    "        return tf.image.random_flip_left_right(img)\n",
    "    def resize(image, height, width):\n",
    "        resized_image = tf.image.resize(image, [height, width])\n",
    "        return resized_image\n",
    "    def train_preprocessing(x):\n",
    "        img = tf.cast(x, dtype=tf.float32)\n",
    "        img = tf.image.resize(img, size=(image_size, image_size), antialias=True)\n",
    "        img = img / 127.5 - 1.0\n",
    "        img = tf.clip_by_value(img, -1.0, 1.0)\n",
    "        img = augment(img)\n",
    "        return img\n",
    "    dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        directory,\n",
    "        label_mode=None,\n",
    "        batch_size=None,\n",
    "        shuffle=True,\n",
    "        seed=123,\n",
    "    )\n",
    "    datasetmapeado = dataset.map(train_preprocessing, num_parallel_calls=tf.data.AUTOTUNE).batch(batch_size, drop_remainder=True)\n",
    "    return datasetmapeado\n",
    "\n",
    "dataset=get_loader(img_size)\n",
    "\n",
    "# Class containing the reverse and forward process\n",
    "class DiffusionProcesses:\n",
    "    def __init__(self, beta_start=1e-4, beta_end=0.02, timesteps=1000):\n",
    "        # Beta vector of 1000 samples for the linear variance schedule is created\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "        self.timesteps = timesteps\n",
    "        self.betas = betas = np.linspace(beta_start, beta_end, timesteps,dtype=np.float64)\n",
    "        \n",
    "        # Alpha vector for the linear variance schedule as 1-beta is created\n",
    "        alphas = 1.0 - betas\n",
    "        alphas_product = np.cumprod(alphas, axis=0)\n",
    "        alphas_product_minus_one = np.append(1.0, alphas_product[:-1])\n",
    "        self.betas = tf.constant(betas, dtype=tf.float32)\n",
    "        \n",
    "        # Product of alpha (t) vector is created\n",
    "        self.alphas_product = tf.constant(alphas_product, dtype=tf.float32)\n",
    "        # Product of alpha (t-1) vector for efficiency (so it's not calculated every time)\n",
    "        self.alphas_product_minus_one = tf.constant(alphas_product_minus_one, dtype=tf.float32)\n",
    "\n",
    "        # The following variables will contain all other operations needed for the forward and reverse process\n",
    "        # (everything can be calculated from alpha and beta, but this increases efficiency and training speed)\n",
    "        # Square root of the product of alpha (t) vector | sqrt(prod(α(t)))\n",
    "        self.sqrt_alphas_product = tf.constant(np.sqrt(alphas_product), dtype=tf.float32)\n",
    "        # Square root of 1 minus the product of alpha (t) vector | sqrt(1-prod(α(t)))\n",
    "        self.sqrt_one_minus_alphas_product = tf.constant(np.sqrt(1.0 - alphas_product), dtype=tf.float32)\n",
    "        # Square root of 1 divided by the product of alpha (t) vector | sqrt(1/prod(α(t)))\n",
    "        self.sqrt_operation_alphas_product = tf.constant(np.sqrt(1.0 / alphas_product), dtype=tf.float32)\n",
    "        # Square root of 1 divided by the product of alpha (t) minus 1 | sqrt(1/(prod(α(t)-1))\n",
    "        self.sqrt_operation_alphas_minus_one_product = tf.constant(np.sqrt(1.0 / alphas_product - 1), dtype=tf.float32)\n",
    "\n",
    "        # Natural logarithm of the variance of q as ln((β*(1-prod(α(t-1))))/(1-prod(α))) (log is used to later calculate the stddev in p_sample as e^(0.5*result(ln)))\n",
    "        posterior_variance = (betas * (1.0 - alphas_product_minus_one)/(1.0 - alphas_product))\n",
    "        self.posterior_variance = tf.constant(posterior_variance, dtype=tf.float32)\n",
    "        self.posterior_log_variance = tf.constant(np.log(np.maximum(posterior_variance, 1e-20)), dtype=tf.float32)\n",
    "\n",
    "        # To calculate the mean of q:\n",
    "        # Mean of generated x as (sqrt(prod(α(t)))*(1-prod(α(t)))/(1-prod(α(t-1)))\n",
    "        self.posterior_mean1 = tf.constant(np.sqrt(alphas)*(1.0 - alphas_product_minus_one)/(1.0 - alphas_product),dtype=tf.float32)\n",
    "        # Mean of reconstructed x as (sqrt(prod(α(t-1)))*β/(1-prod(α))\n",
    "        self.posterior_mean2 = tf.constant(np.sqrt(alphas_product_minus_one)*betas/(1.0 - alphas_product),dtype=tf.float32)\n",
    "        \n",
    "    # Function to correlate vectors with the current time epoch t \n",
    "    def _extract(self, a, t, x_shape):\n",
    "        batch_size = x_shape[0]\n",
    "        out = tf.gather(a, t)\n",
    "        return tf.reshape(out, [batch_size, 1, 1, 1])\n",
    "\n",
    "    # Function to add noise to the image (forward process)\n",
    "    def forward_process(self, x_start, t, noise):\n",
    "        x_start_shape = tf.shape(x_start)\n",
    "        return self._extract(self.sqrt_alphas_product, t, tf.shape(x_start)) * x_start + self._extract(self.sqrt_one_minus_alphas_product, t, x_start_shape)* noise\n",
    "\n",
    "    # Function to calculate the mean and log variance of q\n",
    "    def q_posterior(self, x_recon, xt, t):\n",
    "        xt_shape = tf.shape(xt)\n",
    "        # Mean of q is calculated\n",
    "        q_mean = self._extract(self.posterior_mean1, t, xt_shape) * xt + self._extract(self.posterior_mean2, t, xt_shape) * x_recon\n",
    "        # Log variance of q is calculated\n",
    "        q_log_variance = self._extract(self.posterior_log_variance, t, xt_shape)\n",
    "        return q_mean, q_log_variance\n",
    "\n",
    "    # Function to calculate reconstructed x\n",
    "    def predict_start_from_noise(self, xt, t, noise):\n",
    "        xt_shape = tf.shape(xt)\n",
    "        return self._extract(self.sqrt_operation_alphas_product, t, xt_shape) * xt - self._extract(self.sqrt_operation_alphas_minus_one_product, t, xt_shape) * noise\n",
    "    \n",
    "    # Function to calculate the mean and log variance of p, which is that of q calculated above\n",
    "    def p_mean_and_variance(self, pred_noise, x, t):\n",
    "        # Reconstructed x is calculated \n",
    "        x_recon = self.predict_start_from_noise(x, t=t, noise=pred_noise)\n",
    "        x_recon = tf.clip_by_value(x_recon, -1.0, 1.0)\n",
    "        # q_posterior is called\n",
    "        posterior_mean, posterior_log_variance = self.q_posterior(x_recon=x_recon, xt=x, t=t)\n",
    "        return posterior_mean, posterior_log_variance\n",
    "\n",
    "    # Function to remove noise from the image (reverse process)\n",
    "    def p_sample(self, pred_noise, x, t):\n",
    "        # p_mean_and_variance is called\n",
    "        posterior_mean, posterior_log_variance = self.p_mean_and_variance(pred_noise, x=x, t=t)\n",
    "        # Noise vector z is created\n",
    "        noise = tf.random.normal(shape=x.shape, dtype=x.dtype)\n",
    "        # If t is 0, only the mean is returned\n",
    "        zero = tf.reshape(1 - tf.cast(tf.equal(t, 0), tf.float32), [tf.shape(x)[0], 1, 1, 1])\n",
    "        # Returns μt(xgen,xrec)+σt*z\n",
    "        return posterior_mean + zero * tf.exp(0.5 * posterior_log_variance) * noise\n",
    "\n",
    "# An object of the DiffusionProcesses class is created\n",
    "utils = DiffusionProcesses(timesteps=1000)\n",
    "\n",
    "# Function to initialize the Kernel\n",
    "def kernel_init(scale):\n",
    "    scale = max(scale, 1e-10)\n",
    "    return keras.initializers.VarianceScaling(scale, mode=\"fan_avg\", distribution=\"uniform\")\n",
    "\n",
    "# Sinusoidal positional embedding class for the Transformer\n",
    "class TimeEmbedding(layers.Layer):\n",
    "    def __init__(self, dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dim = dim\n",
    "        self.half_dim = dim // 2\n",
    "        self.emb = math.log(10000) / (self.half_dim - 1)\n",
    "        self.emb = tf.exp(tf.range(self.half_dim, dtype=tf.float32) * -self.emb)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = tf.cast(inputs, dtype=tf.float32)\n",
    "        emb = inputs[:, None] * self.emb[None, :]\n",
    "        emb = tf.concat([tf.sin(emb), tf.cos(emb)], axis=-1)\n",
    "        return emb\n",
    "\n",
    "# Function that introduces the timeEmbedding through an MLP \n",
    "def TimeMLP(units, activation_fn=keras.activations.swish):\n",
    "    def apply(inputs):\n",
    "        # First MLP layer\n",
    "        timeEmbedding = layers.Dense(units, activation=activation_fn, kernel_initializer=kernel_init(1.0))(inputs)\n",
    "        # Second MLP layer\n",
    "        timeEmbedding = layers.Dense(units, kernel_initializer=kernel_init(1.0))(timeEmbedding)\n",
    "        return timeEmbedding\n",
    "    return apply\n",
    "\n",
    "# Attention block class\n",
    "class AttentionBlock(layers.Layer):\n",
    "    def __init__(self, units, groups=8, **kwargs):\n",
    "        self.units = units\n",
    "        self.groups = groups\n",
    "        super().__init__(**kwargs)\n",
    "        # Initializes the GroupNormalization layer\n",
    "        self.norm = tfa.layers.GroupNormalization(groups=groups)\n",
    "        # Initializes the Dense layer for the query\n",
    "        self.query = layers.Dense(units, kernel_initializer=kernel_init(1.0))\n",
    "        # Initializes the Dense layer for the key\n",
    "        self.key = layers.Dense(units, kernel_initializer=kernel_init(1.0))\n",
    "        # Initializes the Dense layer for the value\n",
    "        self.value = layers.Dense(units, kernel_initializer=kernel_init(1.0))\n",
    "        # Initializes the Dense layer for projection\n",
    "        self.proj = layers.Dense(units, kernel_initializer=kernel_init(0.0))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        height = tf.shape(inputs)[1]\n",
    "        width = tf.shape(inputs)[2]\n",
    "        # Scale is set as 1/sqrt(num_channels)\n",
    "        scale = tf.cast(self.units, tf.float32) ** (-0.5)\n",
    "\n",
    "        # Inputs are normalized\n",
    "        inputs = self.norm(inputs)\n",
    "        q = self.query(inputs)\n",
    "        k = self.key(inputs)\n",
    "        v = self.value(inputs)\n",
    "\n",
    "        # Mathmul*Scale is performed\n",
    "        attn_score = tf.einsum(\"bhwc, bHWc->bhwHW\", q, k) * scale\n",
    "        # Similarity is calculated\n",
    "        attn_score = tf.reshape(attn_score, [batch_size, height, width, height * width])\n",
    "        \n",
    "        # Softmax is calculated\n",
    "        attn_score = tf.nn.softmax(attn_score, -1)\n",
    "        attn_score = tf.reshape(attn_score, [batch_size, height, width, height, width])\n",
    "\n",
    "        # Final Mathmul is performed\n",
    "        proj = tf.einsum(\"bhwHW,bHWc->bhwc\", attn_score, v)\n",
    "        proj = self.proj(proj)#Projection\n",
    "        return inputs + proj\n",
    "\n",
    "# Residual block function\n",
    "def ResidualBlock(width, groups=8, activation_fn=keras.activations.swish):\n",
    "    def apply(inputs):\n",
    "        x, t = inputs\n",
    "        input_width = x.shape[3]\n",
    "\n",
    "        # Checks if the input vector dimension matches the output, if so adds input to output\n",
    "        if input_width == width:\n",
    "            add = x\n",
    "        else: # Otherwise, adds input to output after a convolution\n",
    "            add = layers.Conv2D(width, kernel_size=1, kernel_initializer=kernel_init(1.0))(x)\n",
    "\n",
    "        timeEmbedding = activation_fn(t)\n",
    "        # Dense layer used for timeEmbedding\n",
    "        timeEmbedding = layers.Dense(width, kernel_initializer=kernel_init(1.0))(timeEmbedding)[:, None, None, :]\n",
    "        # Group Normalization before the first convolutional layer\n",
    "        x = tfa.layers.GroupNormalization(groups=groups)(x)\n",
    "        x = activation_fn(x)\n",
    "        # First convolution\n",
    "        x = layers.Conv2D(width, kernel_size=3, padding=\"same\", kernel_initializer=kernel_init(1.0))(x)\n",
    "\n",
    "        x = layers.Add()([x, timeEmbedding])\n",
    "        # Group Normalization before the second convolutional layer\n",
    "        x = tfa.layers.GroupNormalization(groups=groups)(x)#GroupNormalization right before the second convolutional layer\n",
    "        x = activation_fn(x)\n",
    "        \n",
    "        # Second convolutional layer that receives the timeEmbedding\n",
    "        x = layers.Conv2D(width, kernel_size=3, padding=\"same\", kernel_initializer=kernel_init(0.0))(x)\n",
    "        x = layers.Add()([x, add])\n",
    "        return x\n",
    "    return apply\n",
    "\n",
    "# DownBlock\n",
    "def DownBlock(width):\n",
    "    def apply(x):\n",
    "        x = layers.Conv2D(width,kernel_size=3,strides=2,padding=\"same\",kernel_initializer=kernel_init(1.0))(x)\n",
    "        return x\n",
    "    return apply\n",
    "\n",
    "\n",
    "def UpBlock(width, interpolation=\"nearest\"):\n",
    "    def apply(x):\n",
    "        x = layers.UpSampling2D(size=2, interpolation=interpolation)(x)\n",
    "        x = layers.Conv2D(width, kernel_size=3, padding=\"same\", kernel_initializer=kernel_init(1.0))(x)\n",
    "        return x\n",
    "\n",
    "    return apply\n",
    "\n",
    "# Modified U-Net function\n",
    "def build_model(img_size,img_channels,filters,isAttentionLevel,nRes_blocks=2,norm_groups=8,interpolation=\"nearest\",activation_fn=keras.activations.swish):\n",
    "    # Input layer for image dimensions\n",
    "    image_input = layers.Input(shape=(img_size, img_size, img_channels), name=\"image_input\")\n",
    "    # Input layer for timeEmbedding dimensions\n",
    "    time_input = keras.Input(shape=(), dtype=tf.int64, name=\"time_input\")\n",
    "    \n",
    "    # First convolutional layer to set the number of input channels for the modified U-Net\n",
    "    x = layers.Conv2D(filters[0],kernel_size=(3, 3),padding=\"same\",kernel_initializer=kernel_init(1.0))(image_input)\n",
    "    timeEmbedding = TimeEmbedding(dim=filters[0] * 4)(time_input)#Creates the Transformer sinusoidal position embedding\n",
    "    timeEmbedding = TimeMLP(units=filters[0] * 4, activation_fn=activation_fn)(timeEmbedding)#Creates the TimeEmbedding\n",
    "\n",
    "    # Initializes the skip connections vector\n",
    "    skips = [x]\n",
    "    # Downsampling blocks loop. As many as there are filters\n",
    "    for i in range(len(filters)):\n",
    "        for _ in range(nRes_blocks):\n",
    "            x = ResidualBlock(filters[i], groups=norm_groups, activation_fn=activation_fn)([x, timeEmbedding])\n",
    "            if isAttentionLevel[i]:\n",
    "                x = AttentionBlock(filters[i], groups=norm_groups)(x)\n",
    "            skips.append(x)\n",
    "        if filters[i] != filters[-1]:\n",
    "            x = DownBlock(filters[i])(x)#DownBlock Blocks\n",
    "            skips.append(x)\n",
    "    \n",
    "    # Middle block\n",
    "    x = ResidualBlock(filters[-1], groups=norm_groups, activation_fn=activation_fn)([x, timeEmbedding])\n",
    "    x = AttentionBlock(filters[-1], groups=norm_groups)(x)\n",
    "    x = ResidualBlock(filters[-1], groups=norm_groups, activation_fn=activation_fn)([x, timeEmbedding])\n",
    "    \n",
    "    # Upsampling blocks loop. As many as there are filters\n",
    "    for i in reversed(range(len(filters))):\n",
    "        for _ in range(nRes_blocks+1):\n",
    "            # Concatenates the output of the parallel downsampling parts with the inputs of the upsampling parts via skip connections\n",
    "            x = layers.Concatenate(axis=-1)([x, skips.pop()])\n",
    "            x = ResidualBlock(filters[i], groups=norm_groups, activation_fn=activation_fn)([x, timeEmbedding])\n",
    "            if isAttentionLevel[i]:\n",
    "                x = AttentionBlock(filters[i], groups=norm_groups)(x)\n",
    "        if i != 0:\n",
    "            x = UpBlock(filters[i], interpolation=interpolation)(x)\n",
    "\n",
    "    # Final block\n",
    "    # Output is normalized with Group Normalization\n",
    "    x = tfa.layers.GroupNormalization(groups=norm_groups)(x)\n",
    "    x = activation_fn(x)\n",
    "    # Output channels are reduced to three dimensions (RGB)\n",
    "    x = layers.Conv2D(3, (3, 3), padding=\"same\", kernel_initializer=kernel_init(0.0))(x)\n",
    "    return keras.Model([image_input, time_input], x, name=\"U-Net_Modified\")\n",
    "\n",
    "# Variable to hold the model is created\n",
    "network = build_model(img_size=img_size,img_channels=3,filters=filters,isAttentionLevel=isAttentionLevel,nRes_blocks=nRes_blocks,norm_groups=norm_groups,activation_fn=keras.activations.swish)\n",
    "\n",
    "# Model is compiled specifying its optimizer and objective function (MSE)\n",
    "optimizer=keras.optimizers.Adam(learning_rate=2e-4)\n",
    "network.compile(loss=keras.losses.MeanSquaredError(),optimizer=optimizer)\n",
    "\n",
    "# Returns the summary of the DDPM\n",
    "network.summary()\n",
    "\n",
    "# DDPM loss function\n",
    "def ddpm_loss(noise, pred_noise):\n",
    "    diffusion_loss = tf.keras.losses.MeanSquaredError()(noise, pred_noise)\n",
    "    return diffusion_loss\n",
    "\n",
    "# Returns images in a format that allows storing them in Tensorboard\n",
    "def plot_to_image(figure):\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "# Creates a 5x5 grid with the received images\n",
    "def image_grid(images):\n",
    "    figure = plt.figure(figsize=(10,10))\n",
    "    for i in range(images.shape[0]):\n",
    "        img = preprocessing.image.array_to_img((images[i] + 1 / 2))\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(img)\n",
    "    return figure\n",
    "\n",
    "# Function to generate images using the reverse process\n",
    "def generate_images(seed, num_images=25):\n",
    "    for t in reversed(range(0, timesteps)):\n",
    "        print(f\"\\rStage t = {t}\", end=\" \")\n",
    "        current_t = tf.cast(tf.fill(num_images, t), dtype=tf.int64)\n",
    "        # Predicted noise is calculated\n",
    "        pred_noise = network.predict([seed, current_t], verbose=0, batch_size=num_images)\n",
    "        # Images are generated by performing the reverse process\n",
    "        seed = utils.p_sample(pred_noise, seed, current_t)\n",
    "    return seed\n",
    "\n",
    "# Function that calls generate_images with samples and saves the generated images in the specified folder\n",
    "def plot_images(folder, seed, epoch=None, logs=None, num_rows=5, num_cols=5, figsize=(5, 5)):\n",
    "    generated_images = generate_images(seed, num_images=num_rows * num_cols)\n",
    "    generated_images = (\n",
    "            tf.clip_by_value(generated_images * 127.5 + 127.5, 0.0, 255.0)\n",
    "            .numpy()\n",
    "            .astype(np.uint8)\n",
    "        )\n",
    "    _, ax = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
    "    for i, image in enumerate(generated_images):\n",
    "        if num_rows == 1:\n",
    "            ax[i].imshow(image)\n",
    "            ax[i].axis(\"off\")\n",
    "        else:\n",
    "            ax[i // num_cols, i % num_cols].imshow(image)\n",
    "            ax[i // num_cols, i % num_cols].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(folder + 'generated_image_epoch_%d.png' % epoch)\n",
    "    plt.close()\n",
    "    return generated_images\n",
    "\n",
    "# Seed is created to always generate the same images and thus compare the network's evolution\n",
    "tf.random.set_seed(347)\n",
    "seed = tf.random.normal(shape=(25, img_size, img_size, 3), dtype=tf.float32)\n",
    "\n",
    "# Network is trained via train_step\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    # Uniform random time vector of 1000 samples is generated\n",
    "    t = tf.random.uniform(minval=0, maxval=timesteps, shape=(batch_size,), dtype=tf.int64)\n",
    "\n",
    "    # Network is trained\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Noise vector to be added to the images is created\n",
    "        noise = tf.random.normal(shape=tf.shape(images), dtype=images.dtype)\n",
    "        # Forward process is called to apply the noise vector to the images\n",
    "        images_t = utils.forward_process(images, t, noise)\n",
    "        # Predicted noise is extracted from the network\n",
    "        pred_noise = network([images_t, t], training=True)\n",
    "        # Network error is calculated\n",
    "        diffusion_loss = ddpm_loss(noise, pred_noise)\n",
    "\n",
    "    # Gradients of the discriminator are updated\n",
    "    gradients = tape.gradient(diffusion_loss, network.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, network.trainable_weights))\n",
    "\n",
    "    # Returns the sum of the network error\n",
    "    return diffusion_loss\n",
    "\n",
    "# Network training function\n",
    "def train(epochs, model):\n",
    "    generated_images=plot_images(generated_images_folder, seed, 0)\n",
    "    for epoch in range(epochs):\n",
    "        print('Current training epoch {} (out of {}).'.format(epoch+1, epochs))\n",
    "        # Loop that iterates over the dataset to train the network\n",
    "        for image_batch in tqdm(dataset):\n",
    "            diffusion_loss=train_step(image_batch)\n",
    "        # Model error is printed in Tensorboard\n",
    "        with tensorboard.as_default():\n",
    "            tf.summary.scalar('Loss Diffusion', diffusion_loss.numpy(), step=epoch)\n",
    "        if epoch % 10 == 0:\n",
    "            generated_images=plot_images(generated_images_folder, seed, epoch)\n",
    "            fig=image_grid(generated_images[:25])\n",
    "            # Images generated by the model are printed in Tensorboard\n",
    "            with tensorboard.as_default():\n",
    "                tf.summary.image('Generated images', plot_to_image(fig), step=epoch)\n",
    "            # Model weights are saved\n",
    "            network.save_weights(trained_models_folder + \"Diffusion_epoch_%d\" % epoch)\n",
    "    # In the last iteration, the model and the last produced images are saved\n",
    "    plot_images(generated_images_folder, seed, epoch)\n",
    "    network.save_weights(trained_models_folder + \"Diffusion_epoch_%d\" % epoch)\n",
    "\n",
    "# Calls the train function to start training\n",
    "train(150,network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aced140",
   "metadata": {},
   "source": [
    "## Cargar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4140e766",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Specify the folder where the trained model will be loaded from (the model must be created before loading, so you could temporarily comment out line 466 of the previous code)\n",
    "epoch = 0  # Specify the epoch of the model you want to load\n",
    "network.load_weights(trained_models_folder + \"Diffusion_epoch_%d\" % epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
