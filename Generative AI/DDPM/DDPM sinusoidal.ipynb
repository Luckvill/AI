{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7a0e192",
   "metadata": {},
   "source": [
    "## Ejecutar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99b7c09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from inspect import isfunction\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow import einsum\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from tensorflow.keras.models import save_model\n",
    "from keras.losses import mse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import preprocessing, Sequential\n",
    "import time\n",
    "import io\n",
    "from tqdm import tqdm\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "# Tensorboard writer is created\n",
    "tensorboard= tf.summary.create_file_writer(logdir='logs/{}'.format(\"Cars{}\".format(int(time.time()))))\n",
    "\n",
    "# Directory where the images for training the network are located\n",
    "directory=\"\" # Format: \"{directory}\"\n",
    "\n",
    "# Image size that the network will generate\n",
    "img_size = 128\n",
    "\n",
    "# Folder where the trained model will be saved\n",
    "trained_models_folder =\"\" # Format: \"{directory}\\ \"\n",
    "\n",
    "# Folder where the images generated by the model will be saved\n",
    "generated_images_folder=\"\" # Format: \"{directory}\\ \"\n",
    "\n",
    "# Batch size\n",
    "batch_size = 12\n",
    "\n",
    "# Number of groups used in Group Normalization\n",
    "norm_groups = 4\n",
    "\n",
    "# Number of timesteps for the forward and reverse process\n",
    "timesteps=1000\n",
    "\n",
    "# Filters to apply in the network\n",
    "filters = [32,64,128,256]\n",
    "\n",
    "# Indicates which levels of the network use attention blocks\n",
    "isAttentionLevel = [False, False, True, True]\n",
    "\n",
    "# Number of residual blocks at each downsampling level (one more for upsampling)\n",
    "nRes_blocks = 2\n",
    "\n",
    "# Loads the car dataset, normalizes and horizontally flips its images\n",
    "def get_loader(image_size):\n",
    "    def augment(img):\n",
    "        return tf.image.random_flip_left_right(img)\n",
    "    def resize(image, height, width):\n",
    "        resized_image = tf.image.resize(image, [height, width])\n",
    "        return resized_image\n",
    "    def train_preprocessing(x):\n",
    "        img = tf.cast(x, dtype=tf.float32)\n",
    "        img = tf.image.resize(img, size=(image_size, image_size), antialias=True)\n",
    "        img = img / 127.5 - 1.0\n",
    "        img = tf.clip_by_value(img, -1.0, 1.0)\n",
    "        img = augment(img)\n",
    "        return img\n",
    "    dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        directory,\n",
    "        label_mode=None,\n",
    "        batch_size=None,\n",
    "        shuffle=True,\n",
    "        seed=123,\n",
    "    )\n",
    "    datasetmapeado = dataset.map(train_preprocessing, num_parallel_calls=tf.data.AUTOTUNE).batch(batch_size, drop_remainder=True)\n",
    "    return datasetmapeado\n",
    "\n",
    "dataset=get_loader(img_size)\n",
    "\n",
    "# Function that creates the sinusoidal variance schedule\n",
    "def beta_sinusoidal(timesteps, alpha_bar, max_beta=0.999):\n",
    "    betas = []\n",
    "    for i in range(timesteps):\n",
    "        t1 = i / timesteps\n",
    "        t2 = (i + 1) / timesteps\n",
    "        betas.append(min(1 - alpha_bar(t2) / alpha_bar(t1), max_beta))\n",
    "    return np.array(betas)\n",
    "\n",
    "# Class containing the reverse and forward process\n",
    "class DiffusionProcesses:\n",
    "    def __init__(self, timesteps=1000):\n",
    "        # Creates a beta vector of 1000 samples for the sinusoidal variance schedule\n",
    "        self.betas = betas = beta_sinusoidal(timesteps,lambda t: math.cos((t + 0.008) / 1.008 * math.pi / 2) ** 2,)\n",
    "        self.timesteps = timesteps\n",
    "        \n",
    "        # Creates the alpha vector for the linear variance schedule as 1-beta\n",
    "        alphas = 1.0 - betas\n",
    "        alphas_product = np.cumprod(alphas, axis=0)\n",
    "        alphas_product_minus_one = np.append(1.0, alphas_product[:-1])\n",
    "        self.betas = tf.constant(betas, dtype=tf.float32)\n",
    "        \n",
    "        # Creates the alpha product vector (t)\n",
    "        self.alphas_product = tf.constant(alphas_product, dtype=tf.float32)\n",
    "        # Creates the alpha product vector (t-1) for efficiency (so it's not calculated every time)\n",
    "        self.alphas_product_minus_one = tf.constant(alphas_product_minus_one, dtype=tf.float32)\n",
    "\n",
    "        # The following variables contain all other operations needed for the forward and reverse process\n",
    "        # (with alpha and beta everything can be calculated, but this increases efficiency and training speed)\n",
    "        # Square root of the alpha product vector (t) | sqrt(prod(α(t)))\n",
    "        self.sqrt_alphas_product = tf.constant(np.sqrt(alphas_product), dtype=tf.float32)\n",
    "        # Square root of 1 minus the alpha product vector (t) | sqrt(1-prod(α(t)))\n",
    "        self.sqrt_one_minus_alphas_product = tf.constant(np.sqrt(1.0 - alphas_product), dtype=tf.float32)\n",
    "        # Square root of 1 divided by the alpha product vector (t) | sqrt(1/prod(α(t)))\n",
    "        self.sqrt_operation_alphas_product = tf.constant(np.sqrt(1.0 / alphas_product), dtype=tf.float32)\n",
    "        # Square root of 1 divided by the alpha product vector (t) minus 1 | sqrt(1/(prod(α(t)-1))\n",
    "        self.sqrt_operation_alphas_minus_one_product = tf.constant(np.sqrt(1.0 / alphas_product - 1), dtype=tf.float32)\n",
    "\n",
    "        # Calculates the natural logarithm of the variance of q as ln((β*(1-prod(α(t-1))))/(1-prod(α))) (the logarithm is used to later calculate the standard deviation in the p_sample function as e^(0.5*result(ln)))\n",
    "        posterior_variance = (betas * (1.0 - alphas_product_minus_one)/(1.0 - alphas_product))\n",
    "        self.posterior_variance = tf.constant(posterior_variance, dtype=tf.float32)\n",
    "        self.posterior_log_variance = tf.constant(np.log(np.maximum(posterior_variance, 1e-20)), dtype=tf.float32)\n",
    "\n",
    "        # To calculate the mean of q:\n",
    "        # Mean of generated x as (sqrt(prod(α(t)))*(1-prod(α(t)))/(1-prod(α(t-1)))\n",
    "        self.posterior_mean1 = tf.constant(np.sqrt(alphas)*(1.0 - alphas_product_minus_one)/(1.0 - alphas_product),dtype=tf.float32)\n",
    "        # Mean of reconstructed x as (sqrt(prod(α(t-1)))*β/(1-prod(α))\n",
    "        self.posterior_mean2 = tf.constant(np.sqrt(alphas_product_minus_one)*betas/(1.0 - alphas_product),dtype=tf.float32)\n",
    "        \n",
    "    # Function to correlate vectors with the current time epoch t \n",
    "    def _extract(self, a, t, x_shape):\n",
    "        batch_size = x_shape[0]\n",
    "        out = tf.gather(a, t)\n",
    "        return tf.reshape(out, [batch_size, 1, 1, 1])\n",
    "\n",
    "    # Function to add noise to the image (forward process)\n",
    "    def forward_process(self, x_start, t, noise):\n",
    "        x_start_shape = tf.shape(x_start)\n",
    "        return self._extract(self.sqrt_alphas_product, t, tf.shape(x_start)) * x_start + self._extract(self.sqrt_one_minus_alphas_product, t, x_start_shape)* noise\n",
    "\n",
    "    # Function to calculate the mean and log variance of q\n",
    "    def q_posterior(self, x_recon, xt, t):\n",
    "        xt_shape = tf.shape(xt)\n",
    "        # Calculates the mean of q\n",
    "        q_mean = self._extract(self.posterior_mean1, t, xt_shape) * xt + self._extract(self.posterior_mean2, t, xt_shape) * x_recon\n",
    "        # Calculates the log variance of q\n",
    "        q_log_variance = self._extract(self.posterior_log_variance, t, xt_shape)\n",
    "        return q_mean, q_log_variance\n",
    "\n",
    "    # Function to calculate reconstructed x\n",
    "    def predict_start_from_noise(self, xt, t, noise):\n",
    "        xt_shape = tf.shape(xt)\n",
    "        return self._extract(self.sqrt_operation_alphas_product, t, xt_shape) * xt - self._extract(self.sqrt_operation_alphas_minus_one_product, t, xt_shape) * noise\n",
    "    \n",
    "    # Function to calculate the mean and log variance of p, which is that of q calculated in the previous function\n",
    "    def p_mean_and_variance(self, pred_noise, x, t):\n",
    "        # Calculates reconstructed x \n",
    "        x_recon = self.predict_start_from_noise(x, t=t, noise=pred_noise)\n",
    "        x_recon = tf.clip_by_value(x_recon, -1.0, 1.0)\n",
    "        # Calls q_posterior\n",
    "        posterior_mean, posterior_log_variance = self.q_posterior(x_recon=x_recon, xt=x, t=t)\n",
    "        return posterior_mean, posterior_log_variance\n",
    "\n",
    "    # Function to remove noise from the image (reverse process)\n",
    "    def p_sample(self, pred_noise, x, t):\n",
    "        # Calls p_mean_and_variance\n",
    "        posterior_mean, posterior_log_variance = self.p_mean_and_variance(pred_noise, x=x, t=t)\n",
    "        # Creates the noise vector z\n",
    "        noise = tf.random.normal(shape=x.shape, dtype=x.dtype)\n",
    "        # If t is 0, only the mean is returned\n",
    "        zero = tf.reshape(1 - tf.cast(tf.equal(t, 0), tf.float32), [tf.shape(x)[0], 1, 1, 1])\n",
    "        # Returns the result of μt(xgen,xrec)+σt*z\n",
    "        return posterior_mean + zero * tf.exp(0.5 * posterior_log_variance) * noise\n",
    "\n",
    "# Creates an object with the DiffusionProcesses class\n",
    "utils = DiffusionProcesses(timesteps=1000)\n",
    "\n",
    "# Function that initializes the Kernel\n",
    "def kernel_init(scale):\n",
    "    scale = max(scale, 1e-10)\n",
    "    return keras.initializers.VarianceScaling(scale, mode=\"fan_avg\", distribution=\"uniform\")\n",
    "\n",
    "# Sinusoidal position embedding layer for the Transformer\n",
    "class TimeEmbedding(layers.Layer):\n",
    "    def __init__(self, dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dim = dim\n",
    "        self.half_dim = dim // 2\n",
    "        self.emb = math.log(10000) / (self.half_dim - 1)\n",
    "        self.emb = tf.exp(tf.range(self.half_dim, dtype=tf.float32) * -self.emb)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = tf.cast(inputs, dtype=tf.float32)\n",
    "        emb = inputs[:, None] * self.emb[None, :]\n",
    "        emb = tf.concat([tf.sin(emb), tf.cos(emb)], axis=-1)\n",
    "        return emb\n",
    "\n",
    "# Function that passes the timeEmbedding through an MLP \n",
    "def TimeMLP(units, activation_fn=keras.activations.swish):\n",
    "    def apply(inputs):\n",
    "        # First MLP layer\n",
    "        timeEmbedding = layers.Dense(units, activation=activation_fn, kernel_initializer=kernel_init(1.0))(inputs)\n",
    "        # Second MLP layer\n",
    "        timeEmbedding = layers.Dense(units, kernel_initializer=kernel_init(1.0))(timeEmbedding)\n",
    "        return timeEmbedding\n",
    "    return apply\n",
    "\n",
    "# Attention block class\n",
    "class AttentionBlock(layers.Layer):\n",
    "    def __init__(self, units, groups=8, **kwargs):\n",
    "        self.units = units\n",
    "        self.groups = groups\n",
    "        super().__init__(**kwargs)\n",
    "        # Initializes the GroupNormalization layer\n",
    "        self.norm = tfa.layers.GroupNormalization(groups=groups)\n",
    "        # Initializes the Dense layer for the query\n",
    "        self.query = layers.Dense(units, kernel_initializer=kernel_init(1.0))\n",
    "        # Initializes the Dense layer for the key\n",
    "        self.key = layers.Dense(units, kernel_initializer=kernel_init(1.0))\n",
    "        # Initializes the Dense layer for the value\n",
    "        self.value = layers.Dense(units, kernel_initializer=kernel_init(1.0))\n",
    "        # Initializes the Dense layer for the projection\n",
    "        self.proj = layers.Dense(units, kernel_initializer=kernel_init(0.0))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        height = tf.shape(inputs)[1]\n",
    "        width = tf.shape(inputs)[2]\n",
    "        # Scale is set as 1/sqrt(num_channels)\n",
    "        scale = tf.cast(self.units, tf.float32) ** (-0.5)\n",
    "\n",
    "        # Inputs are normalized\n",
    "        inputs = self.norm(inputs)\n",
    "        q = self.query(inputs)\n",
    "        k = self.key(inputs)\n",
    "        v = self.value(inputs)\n",
    "\n",
    "        # Mathmul*Scale\n",
    "        attn_score = tf.einsum(\"bhwc, bHWc->bhwHW\", q, k) * scale\n",
    "        # Similarity calculation\n",
    "        attn_score = tf.reshape(attn_score, [batch_size, height, width, height * width])\n",
    "        \n",
    "        # Softmax calculation\n",
    "        attn_score = tf.nn.softmax(attn_score, -1)\n",
    "        attn_score = tf.reshape(attn_score, [batch_size, height, width, height, width])\n",
    "\n",
    "        # Final Mathmul\n",
    "        proj = tf.einsum(\"bhwHW,bHWc->bhwc\", attn_score, v)\n",
    "        proj = self.proj(proj)#Projection\n",
    "        return inputs + proj\n",
    "\n",
    "# Residual block function\n",
    "def ResidualBlock(width, groups=8, activation_fn=keras.activations.swish):\n",
    "    def apply(inputs):\n",
    "        x, t = inputs\n",
    "        input_width = x.shape[3]\n",
    "\n",
    "        # Checks if the input vector dimension matches the output, if so adds the input to the output\n",
    "        if input_width == width:\n",
    "            residual = x\n",
    "        else: # Otherwise, adds the input to the output after a convolution\n",
    "            residual = layers.Conv2D(width, kernel_size=1, kernel_initializer=kernel_init(1.0))(x)\n",
    "\n",
    "        timeEmbedding = activation_fn(t)\n",
    "        # Dense layer for the timeEmbedding\n",
    "        timeEmbedding = layers.Dense(width, kernel_initializer=kernel_init(1.0))(timeEmbedding)[:, None, None, :]\n",
    "        # Group Normalization before the first convolutional layer\n",
    "        x = tfa.layers.GroupNormalization(groups=groups)(x)\n",
    "        x = activation_fn(x)\n",
    "        # First convolution\n",
    "        x = layers.Conv2D(width, kernel_size=3, padding=\"same\", kernel_initializer=kernel_init(1.0))(x)\n",
    "\n",
    "        x = layers.Add()([x, timeEmbedding])\n",
    "        # Group Normalization before the second convolutional layer\n",
    "        x = tfa.layers.GroupNormalization(groups=groups)(x)#GroupNormalization right before the second convolutional layer\n",
    "        x = activation_fn(x)\n",
    "        \n",
    "        # Second convolutional layer that receives the timeEmbedding\n",
    "        x = layers.Conv2D(width, kernel_size=3, padding=\"same\", kernel_initializer=kernel_init(0.0))(x)\n",
    "        x = layers.Add()([x, residual])\n",
    "        return x\n",
    "    return apply\n",
    "\n",
    "# DownBlock\n",
    "def DownBlock(width):\n",
    "    def apply(x):\n",
    "        x = layers.Conv2D(width,kernel_size=3,strides=2,padding=\"same\",kernel_initializer=kernel_init(1.0))(x)\n",
    "        return x\n",
    "    return apply\n",
    "\n",
    "\n",
    "def UpBlock(width, interpolation=\"nearest\"):\n",
    "    def apply(x):\n",
    "        x = layers.UpSampling2D(size=2, interpolation=interpolation)(x)\n",
    "        x = layers.Conv2D(width, kernel_size=3, padding=\"same\", kernel_initializer=kernel_init(1.0))(x)\n",
    "        return x\n",
    "\n",
    "    return apply\n",
    "\n",
    "# Modified U-Net function\n",
    "def build_model(img_size,img_channels,filters,isAttentionLevel,nRes_blocks=2,norm_groups=8,interpolation=\"nearest\",activation_fn=keras.activations.swish):\n",
    "    # Input layer for image dimensions\n",
    "    image_input = layers.Input(shape=(img_size, img_size, img_channels), name=\"image_input\")\n",
    "    # Input layer for timeEmbedding dimensions\n",
    "    time_input = keras.Input(shape=(), dtype=tf.int64, name=\"time_input\")\n",
    "    \n",
    "    # First convolutional layer to set the number of channels for the input to the modified U-Net\n",
    "    x = layers.Conv2D(filters[0],kernel_size=(3, 3),padding=\"same\",kernel_initializer=kernel_init(1.0))(image_input)\n",
    "    timeEmbedding = TimeEmbedding(dim=filters[0] * 4)(time_input)#Creates the Transformer sinusoidal position embedding\n",
    "    timeEmbedding = TimeMLP(units=filters[0] * 4, activation_fn=activation_fn)(timeEmbedding)#Creates the TimeEmbedding\n",
    "\n",
    "    # Initializes the skip connections vector\n",
    "    skips = [x]\n",
    "    # Downsampling blocks loop. As many as there are filters\n",
    "    for i in range(len(filters)):\n",
    "        for _ in range(nRes_blocks):\n",
    "            x = ResidualBlock(filters[i], groups=norm_groups, activation_fn=activation_fn)([x, timeEmbedding])\n",
    "            if isAttentionLevel[i]:\n",
    "                x = AttentionBlock(filters[i], groups=norm_groups)(x)\n",
    "            skips.append(x)\n",
    "        if filters[i] != filters[-1]:\n",
    "            x = DownBlock(filters[i])(x)#DownBlock Blocks\n",
    "            skips.append(x)\n",
    "    \n",
    "    # Middle block\n",
    "    x = ResidualBlock(filters[-1], groups=norm_groups, activation_fn=activation_fn)([x, timeEmbedding])\n",
    "    x = AttentionBlock(filters[-1], groups=norm_groups)(x)\n",
    "    x = ResidualBlock(filters[-1], groups=norm_groups, activation_fn=activation_fn)([x, timeEmbedding])\n",
    "    \n",
    "    # Upsampling blocks loop. As many as there are filters\n",
    "    for i in reversed(range(len(filters))):\n",
    "        for _ in range(nRes_blocks+1):\n",
    "            # Concatenates the output of the parallel downsampling parts with the inputs of the upsampling parts via skip connections\n",
    "            x = layers.Concatenate(axis=-1)([x, skips.pop()])\n",
    "            x = ResidualBlock(filters[i], groups=norm_groups, activation_fn=activation_fn)([x, timeEmbedding])\n",
    "            if isAttentionLevel[i]:\n",
    "                x = AttentionBlock(filters[i], groups=norm_groups)(x)\n",
    "        if i != 0:\n",
    "            x = UpBlock(filters[i], interpolation=interpolation)(x)\n",
    "\n",
    "    # Final block\n",
    "    # Output is normalized with Group Normalization\n",
    "    x = tfa.layers.GroupNormalization(groups=norm_groups)(x)\n",
    "    x = activation_fn(x)\n",
    "    # Output channels are reduced to three dimensions (RGB)\n",
    "    x = layers.Conv2D(3, (3, 3), padding=\"same\", kernel_initializer=kernel_init(0.0))(x)\n",
    "    return keras.Model([image_input, time_input], x, name=\"U-Net_Modified\")\n",
    "\n",
    "# Variable to hold the model\n",
    "network = build_model(img_size=img_size,img_channels=3,filters=filters,isAttentionLevel=isAttentionLevel,nRes_blocks=nRes_blocks,norm_groups=norm_groups,activation_fn=keras.activations.swish)\n",
    "\n",
    "# Compile the model specifying its optimizer and objective function (MSE)\n",
    "optimizer=keras.optimizers.Adam(learning_rate=2e-4)\n",
    "network.compile(loss=keras.losses.MeanSquaredError(),optimizer=optimizer)\n",
    "\n",
    "# Returns the DDPM summary\n",
    "network.summary()\n",
    "\n",
    "# DDPM loss function\n",
    "def ddpm_loss(noise, pred_noise):\n",
    "    diffusion_loss = tf.keras.losses.MeanSquaredError()(noise, pred_noise)\n",
    "    return diffusion_loss\n",
    "\n",
    "# Returns images in a format that allows storing them in Tensorboard\n",
    "def plot_to_image(figure):\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "# Creates a 5x5 grid with the received images\n",
    "def image_grid(images):\n",
    "    figure = plt.figure(figsize=(10,10))\n",
    "    for i in range(images.shape[0]):\n",
    "        img = preprocessing.image.array_to_img((images[i] + 1 / 2))\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(img)\n",
    "    return figure\n",
    "\n",
    "# Function to generate images using the reverse process\n",
    "def generate_images(seed, num_images=25):\n",
    "    for t in reversed(range(0, timesteps)):\n",
    "        print(f\"\\rStage t = {t}\", end=\" \")\n",
    "        current_t = tf.cast(tf.fill(num_images, t), dtype=tf.int64)\n",
    "        # Calculates the predicted noise\n",
    "        pred_noise = network.predict([seed, current_t], verbose=0, batch_size=num_images)\n",
    "        # Generates images using the reverse process\n",
    "        seed = utils.p_sample(pred_noise, seed, current_t)\n",
    "    return seed\n",
    "\n",
    "# Calls generate_images with samples and saves the generated images in the specified folder\n",
    "def plot_images(folder, seed, epoch=None, logs=None, num_rows=5, num_cols=5, figsize=(5, 5)):\n",
    "    generated_images = generate_images(seed, num_images=num_rows * num_cols)\n",
    "    generated_images = (\n",
    "            tf.clip_by_value(generated_images * 127.5 + 127.5, 0.0, 255.0)\n",
    "            .numpy()\n",
    "            .astype(np.uint8)\n",
    "        )\n",
    "    _, ax = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
    "    for i, image in enumerate(generated_images):\n",
    "        if num_rows == 1:\n",
    "            ax[i].imshow(image)\n",
    "            ax[i].axis(\"off\")\n",
    "        else:\n",
    "            ax[i // num_cols, i % num_cols].imshow(image)\n",
    "            ax[i // num_cols, i % num_cols].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(folder + 'generated_image_epoch_%d.png' % epoch)\n",
    "    plt.close()\n",
    "    return generated_images\n",
    "\n",
    "# Creates a seed to always generate the same images for comparison of network evolution\n",
    "tf.random.set_seed(347)\n",
    "seed = tf.random.normal(shape=(25, img_size, img_size, 3), dtype=tf.float32)\n",
    "\n",
    "# Trains the network via train_step\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    # Generates a random uniform time vector of 1000 samples\n",
    "    t = tf.random.uniform(minval=0, maxval=timesteps, shape=(batch_size,), dtype=tf.int64)\n",
    "\n",
    "    # Trains the network\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Creates the noise vector to be added to the images\n",
    "        noise = tf.random.normal(shape=tf.shape(images), dtype=images.dtype)\n",
    "        # Calls the forward process to apply the noise vector to the images\n",
    "        images_t = utils.forward_process(images, t, noise)\n",
    "        # Extracts the predicted noise from the network\n",
    "        pred_noise = network([images_t, t], training=True)\n",
    "        # Calculates the network error\n",
    "        diffusion_loss = ddpm_loss(noise, pred_noise)\n",
    "\n",
    "    # Updates the gradients of the discriminator\n",
    "    gradients = tape.gradient(diffusion_loss, network.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, network.trainable_weights))\n",
    "\n",
    "    # Returns the sum of the network error\n",
    "    return diffusion_loss\n",
    "\n",
    "# Network training function\n",
    "def train(epochs, model):\n",
    "    generated_images=plot_images(generated_images_folder, seed, 0)\n",
    "    for epoch in range(epochs):\n",
    "        print('Current training epoch {} (out of {}).'.format(epoch+1, epochs))\n",
    "        # Loop that iterates over the dataset to train the network\n",
    "        for image_batch in tqdm(dataset):\n",
    "            diffusion_loss=train_step(image_batch)\n",
    "        # Prints the model error in Tensorboard\n",
    "        with tensorboard.as_default():\n",
    "            tf.summary.scalar('Loss Diffusion', diffusion_loss.numpy(), step=epoch)\n",
    "        if epoch % 10 == 0:\n",
    "            generated_images=plot_images(generated_images_folder, seed, epoch)\n",
    "            fig=image_grid(generated_images[:25])\n",
    "            # Prints the images generated by the model in Tensorboard\n",
    "            with tensorboard.as_default():\n",
    "                tf.summary.image('Generated images', plot_to_image(fig), step=epoch)\n",
    "            # Saves the model weights\n",
    "            network.save_weights(trained_models_folder + \"Diffusion_epoch_%d\" % epoch)\n",
    "    # In the last iteration, saves the model and the last produced images\n",
    "    plot_images(generated_images_folder, seed, epoch)\n",
    "    network.save_weights(trained_models_folder + \"Diffusion_epoch_%d\" % epoch)\n",
    "\n",
    "# Calls the train function to start training\n",
    "train(150,network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a1c4ee",
   "metadata": {},
   "source": [
    "## Cargar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4140e766",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Specify the folder where the trained model will be loaded from (the model must be created before loading, so you could temporarily comment out line 473 of the previous code)\n",
    "epoch = 0  # Specify the epoch of the model you want to load\n",
    "network.load_weights(trained_models_folder + \"Diffusion_epoch_%d\" % epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
