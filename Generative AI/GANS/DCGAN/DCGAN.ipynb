{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5349afa2",
   "metadata": {},
   "source": [
    "## Funciones utilizadas para Differentiable Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ddba17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Functions for Differentiable Augmentation\n",
    "def DiffAugment(x, policy='', channels_first=False):\n",
    "    if policy:\n",
    "        if channels_first:\n",
    "            x = tf.transpose(x, [0, 2, 3, 1])\n",
    "        for p in policy.split(','):\n",
    "            for f in AUGMENT_FNS[p]:\n",
    "                x = f(x)\n",
    "        if channels_first:\n",
    "            x = tf.transpose(x, [0, 3, 1, 2])\n",
    "    return x\n",
    "\n",
    "# Function to randomly change image brightness\n",
    "def rand_brightness(x):\n",
    "    magnitude = tf.random.uniform([tf.shape(x)[0], 1, 1, 1]) - 0.5\n",
    "    x = x + magnitude\n",
    "    return x\n",
    "\n",
    "# Function to randomly change image saturation\n",
    "def rand_saturation(x):\n",
    "    magnitude = tf.random.uniform([tf.shape(x)[0], 1, 1, 1]) * 2\n",
    "    x_mean = tf.reduce_mean(x, axis=3, keepdims=True)\n",
    "    x = (x - x_mean) * magnitude + x_mean\n",
    "    return x\n",
    "\n",
    "# Function to randomly change image contrast\n",
    "def rand_contrast(x):\n",
    "    magnitude = tf.random.uniform([tf.shape(x)[0], 1, 1, 1]) + 0.5\n",
    "    x_mean = tf.reduce_mean(x, axis=[1, 2, 3], keepdims=True)\n",
    "    x = (x - x_mean) * magnitude + x_mean\n",
    "    return x\n",
    "\n",
    "# Function to randomly translate images\n",
    "def rand_translation(x, ratio=0.125):\n",
    "    batch_size = tf.shape(x)[0]\n",
    "    image_size = tf.shape(x)[1:3]\n",
    "    shift = tf.cast(tf.cast(image_size, tf.float32) * ratio + 0.5, tf.int32)\n",
    "    translation_x = tf.random.uniform([batch_size, 1], -shift[0], shift[0] + 1, dtype=tf.int32)\n",
    "    translation_y = tf.random.uniform([batch_size, 1], -shift[1], shift[1] + 1, dtype=tf.int32)\n",
    "    grid_x = tf.clip_by_value(tf.expand_dims(tf.range(image_size[0], dtype=tf.int32), 0) + translation_x + 1, 0, image_size[0] + 1)\n",
    "    grid_y = tf.clip_by_value(tf.expand_dims(tf.range(image_size[1], dtype=tf.int32), 0) + translation_y + 1, 0, image_size[1] + 1)\n",
    "    x = tf.gather_nd(tf.pad(x, [[0, 0], [1, 1], [0, 0], [0, 0]]), tf.expand_dims(grid_x, -1), batch_dims=1)\n",
    "    x = tf.transpose(tf.gather_nd(tf.pad(tf.transpose(x, [0, 2, 1, 3]), [[0, 0], [1, 1], [0, 0], [0, 0]]), tf.expand_dims(grid_y, -1), batch_dims=1), [0, 2, 1, 3])\n",
    "    return x\n",
    "\n",
    "# Function to randomly cut out parts of images\n",
    "def rand_cutout(x, ratio=0.5):\n",
    "    batch_size = tf.shape(x)[0]\n",
    "    image_size = tf.shape(x)[1:3]\n",
    "    cutout_size = tf.cast(tf.cast(image_size, tf.float32) * ratio + 0.5, tf.int32)\n",
    "    offset_x = tf.random.uniform([tf.shape(x)[0], 1, 1], maxval=image_size[0] + (1 - cutout_size[0] % 2), dtype=tf.int32)\n",
    "    offset_y = tf.random.uniform([tf.shape(x)[0], 1, 1], maxval=image_size[1] + (1 - cutout_size[1] % 2), dtype=tf.int32)\n",
    "    grid_batch, grid_x, grid_y = tf.meshgrid(tf.range(batch_size, dtype=tf.int32), tf.range(cutout_size[0], dtype=tf.int32), tf.range(cutout_size[1], dtype=tf.int32), indexing='ij')\n",
    "    cutout_grid = tf.stack([grid_batch, grid_x + offset_x - cutout_size[0] // 2, grid_y + offset_y - cutout_size[1] // 2], axis=-1)\n",
    "    mask_shape = tf.stack([batch_size, image_size[0], image_size[1]])\n",
    "    cutout_grid = tf.maximum(cutout_grid, 0)\n",
    "    cutout_grid = tf.minimum(cutout_grid, tf.reshape(mask_shape - 1, [1, 1, 1, 3]))\n",
    "    mask = tf.maximum(1 - tf.scatter_nd(cutout_grid, tf.ones([batch_size, cutout_size[0], cutout_size[1]], dtype=tf.float32), mask_shape), 0)\n",
    "    x = x * tf.expand_dims(mask, axis=3)\n",
    "    return x\n",
    "\n",
    "\n",
    "AUGMENT_FNS = {\n",
    "    'color': [rand_brightness, rand_saturation, rand_contrast],\n",
    "    'translation': [rand_translation],\n",
    "    'cutout': [rand_cutout],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e71d68b",
   "metadata": {},
   "source": [
    "## Ejecutar los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ce2f38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Input, Conv2D, Dense, Flatten, BatchNormalization, LeakyReLU, ReLU, Reshape, Conv2DTranspose\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import preprocessing, Sequential\n",
    "import time\n",
    "import io\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Tensorboard writer is created\n",
    "tensorboard= tf.summary.create_file_writer(logdir='logs/{}'.format(\"Cars{}\".format(int(time.time()))))\n",
    "\n",
    "# Directory where the images for training the network are located\n",
    "directory=\"\" # Format: \"{directory}\"\n",
    "\n",
    "# Desired image size for the network to generate\n",
    "img_size = 128\n",
    "\n",
    "# Folder to save the trained model\n",
    "trained_models_folder =\"\" # Format: \"{directory}\\ \"\n",
    "\n",
    "# Folder to save the images generated by the model\n",
    "generated_images_folder=\"\" # Format: \"{directory}\\ \"\n",
    "\n",
    "# Batch size\n",
    "batch_size = 50\n",
    "\n",
    "# Latent space dimension\n",
    "latent_dim=100\n",
    "\n",
    "# Loads the car dataset, normalizes and resizes its images\n",
    "def get_loader(img_size):\n",
    "    def train_preprocessing(x):\n",
    "        x = tf.cast(x, tf.float32)\n",
    "        x = x / 255.0  # normalization\n",
    "        return x\n",
    "    dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        directory,\n",
    "        label_mode=None,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        seed=123,\n",
    "        image_size=(img_size, img_size),\n",
    "    )\n",
    "    datasetmapeado = dataset.map(lambda x: train_preprocessing(x))\n",
    "    return datasetmapeado\n",
    "\n",
    "dataset=get_loader(img_size)\n",
    "\n",
    "\n",
    "# Builds the generator\n",
    "def get_generator(latent_dim):\n",
    "    # Initializes the generator weights with a normal distribution (stddev 0.02, mean 0.0) as in the original paper\n",
    "    initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
    "    generator = Sequential(name='Generator')\n",
    "\n",
    "    generator.add(Input(shape=(latent_dim,)))\n",
    "    # Converts input to shape (8,8,1024)\n",
    "    generator.add(Dense(8 * 8 * 1024))\n",
    "    generator.add(Reshape((8, 8, 1024)))\n",
    "\n",
    "    # Converts the vector to shape (16,16,512)\n",
    "    generator.add(Conv2DTranspose(512, kernel_size=5, strides=2, padding='same',kernel_initializer=initializer, use_bias=False))\n",
    "    generator.add(BatchNormalization(momentum=0.1, epsilon=0.8, center=1.0, scale=0.02))\n",
    "    generator.add(ReLU())\n",
    "\n",
    "    # Converts the vector to shape (32,32,256)\n",
    "    generator.add(Conv2DTranspose(256, kernel_size=5, strides=2, padding='same',kernel_initializer=initializer, use_bias=False))\n",
    "    generator.add(BatchNormalization(momentum=0.1, epsilon=0.8, center=1.0, scale=0.02))\n",
    "    generator.add(ReLU())\n",
    "\n",
    "    # Converts the vector to shape (64,64,128)\n",
    "    generator.add(Conv2DTranspose(128, kernel_size=5, strides=2, padding='same',kernel_initializer=initializer, use_bias=False))\n",
    "    generator.add(BatchNormalization(momentum=0.1, epsilon=0.8, center=1.0, scale=0.02))\n",
    "    generator.add(ReLU())\n",
    "\n",
    "    # Converts the vector to shape (128,128,64)\n",
    "    generator.add(Conv2DTranspose(64, kernel_size=5, strides=2, padding='same',kernel_initializer=initializer, use_bias=False))\n",
    "    generator.add(BatchNormalization(momentum=0.1, epsilon=0.8, center=1.0, scale=0.02))\n",
    "    generator.add(ReLU())\n",
    "\n",
    "    # Converts the vector to shape (128,128,3)\n",
    "    generator.add(Conv2D(3, kernel_size=5, strides=1, padding='same',kernel_initializer=initializer, use_bias=False, activation='tanh'))\n",
    "\n",
    "    return generator\n",
    "\n",
    "# Builds the discriminator\n",
    "def get_discriminator():\n",
    "    # Initializes the discriminator weights with a normal distribution (stddev 0.02, mean 0.0) as in the original paper\n",
    "    initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
    "    discriminator = Sequential(name='Discriminator')\n",
    "    discriminator.add(Input(shape=(128, 128, 3)))\n",
    "\n",
    "    # Converts the vector to shape (64,64,64)\n",
    "    discriminator.add(Conv2D(64, kernel_size=5, strides=2, padding=\"same\", kernel_initializer=initializer, use_bias=False))\n",
    "    discriminator.add(BatchNormalization(momentum=0.1, epsilon=0.8, center=1.0, scale=0.02))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "\n",
    "    # Converts the vector to shape (32,32,128)\n",
    "    discriminator.add(Conv2D(128, kernel_size=5, strides=2, padding=\"same\", kernel_initializer=initializer, use_bias=False))\n",
    "    discriminator.add(BatchNormalization(momentum=0.1, epsilon=0.8, center=1.0, scale=0.02))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "\n",
    "    # Converts the vector to shape (16,16,256)\n",
    "    discriminator.add(Conv2D(256, kernel_size=5, strides=2, padding=\"same\",kernel_initializer=initializer, use_bias=False))\n",
    "    discriminator.add(BatchNormalization(momentum=0.1, epsilon=0.8, center=1.0, scale=0.02))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "\n",
    "    # Converts the vector to shape (8,8,512)\n",
    "    discriminator.add(Conv2D(512, kernel_size=5, strides=2, padding=\"same\",kernel_initializer=initializer, use_bias=False))\n",
    "    discriminator.add(BatchNormalization(momentum=0.1, epsilon=0.8, center=1.0, scale=0.02))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "\n",
    "    # Converts the vector to shape (4,4,1024)\n",
    "    discriminator.add(Conv2D(1024, kernel_size=5, strides=2, padding=\"same\",kernel_initializer=initializer, use_bias=False))\n",
    "    discriminator.add(BatchNormalization(momentum=0.1, epsilon=0.8, center=1.0, scale=0.02))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    # Converts the vector to shape (batch size, 1)\n",
    "    discriminator.add(Flatten())\n",
    "    discriminator.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return discriminator\n",
    "\n",
    "# Variables to hold the generator and discriminator models\n",
    "generator=get_generator(latent_dim)\n",
    "discriminator=get_discriminator()\n",
    "\n",
    "# Loss function used\n",
    "binary_cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "# Generator loss function\n",
    "def generator_loss(label, fake_output):\n",
    "    gen_loss = binary_cross_entropy(label, fake_output)\n",
    "    return gen_loss\n",
    "\n",
    "# Discriminator loss function\n",
    "def discriminator_loss(label, output):\n",
    "    disc_loss = binary_cross_entropy(label, output)\n",
    "    return disc_loss\n",
    "\n",
    "# Initialize optimizers for generator and discriminator\n",
    "gen_optimizer = disc_optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "# Compile the models specifying their optimizers and loss function (Binary Cross Entropy)\n",
    "generator.compile(gen_optimizer, loss=binary_cross_entropy)\n",
    "discriminator.compile(disc_optimizer, loss=binary_cross_entropy)\n",
    "\n",
    "# Print the summary of the generator and discriminator\n",
    "generator.summary()\n",
    "discriminator.summary()\n",
    "\n",
    "# Returns images in a format that can be stored in Tensorboard\n",
    "def plot_to_image(figure):\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "# Creates a 5x5 grid with the received images\n",
    "def image_grid(images):\n",
    "    figure = plt.figure(figsize=(10,10))\n",
    "    for i in range(images.shape[0]):\n",
    "        img = preprocessing.image.array_to_img((images[i] + 1 / 2))\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(img)\n",
    "    return figure\n",
    "\n",
    "# Generates and saves the images produced by the generator in a local folder\n",
    "def generate_and_save_images(folder, model, epoch, seed, dim=(5, 5), figsize=(10, 10)):\n",
    "    generated_images = model(seed)\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        img = preprocessing.image.array_to_img((generated_images[i] + 1 / 2))\n",
    "        plt.imshow(img)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(folder + 'generated_image_epoch_%d.png' % epoch)\n",
    "    plt.close()\n",
    "    return generated_images\n",
    "\n",
    "# Trains the network via train_step\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    # Generates a vector of random images (noise)\n",
    "    noise = tf.random.normal([batch_size, latent_dim])\n",
    "    \n",
    "    # Processes the batch images with Differentiable Augmentation\n",
    "    images = DiffAugment(images, policy='color,translation,cutout')\n",
    "\n",
    "    # Trains the discriminator with real images\n",
    "    with tf.GradientTape() as disc_tapeReal:\n",
    "        # Discriminator predictions for real images\n",
    "        real_preds = discriminator(images, training=True)\n",
    "        # Creates a vector of 1's multiplied by 0.9 to encourage learning, indicating real images\n",
    "        unos = tf.ones_like(real_preds) * 0.9\n",
    "        # Calculates discriminator loss with real images\n",
    "        disc_lossReal = discriminator_loss(unos, real_preds)\n",
    "\n",
    "    # Updates discriminator gradients\n",
    "    gradients_discReal = disc_tapeReal.gradient(disc_lossReal, discriminator.trainable_variables)\n",
    "    disc_optimizer.apply_gradients(zip(gradients_discReal, discriminator.trainable_variables))\n",
    "\n",
    "    # Trains the discriminator with fake images\n",
    "    with tf.GradientTape() as disc_tapeFake:\n",
    "        # Generates fake images with the generator\n",
    "        generated_images = generator(noise, training=True)\n",
    "        # Processes the generated fake images with Differentiable Augmentation\n",
    "        generated_images = DiffAugment(generated_images, policy='color,translation,cutout')\n",
    "        # Discriminator predictions for fake images\n",
    "        fake_preds = discriminator(generated_images, training=True)\n",
    "        # Creates a vector of 0's indicating fake images\n",
    "        ceros = tf.zeros_like(fake_preds)\n",
    "        # Calculates discriminator loss with fake images\n",
    "        disc_lossFake = discriminator_loss(ceros, fake_preds)\n",
    "\n",
    "    # Updates discriminator gradients\n",
    "    gradients_discFake = disc_tapeFake.gradient(disc_lossFake, discriminator.trainable_variables)\n",
    "    disc_optimizer.apply_gradients(zip(gradients_discFake, discriminator.trainable_variables))\n",
    "\n",
    "    # Trains the generator\n",
    "    with tf.GradientTape() as gen_tape:\n",
    "        # Generates fake images with the generator\n",
    "        generated_images = generator(noise, training=True)\n",
    "        # Processes the generated fake images with Differentiable Augmentation\n",
    "        generated_images = DiffAugment(generated_images, policy='color,translation,cutout')\n",
    "        # Discriminator predictions for fake images\n",
    "        fake_preds = discriminator(generated_images, training=True)\n",
    "        # \"Tricks\" the discriminator with a vector of 1's so it thinks the generated images are real and the generator learns\n",
    "        unos = tf.ones_like(fake_preds)\n",
    "        # Calculates generator loss\n",
    "        gen_loss = generator_loss(unos, fake_preds)\n",
    "\n",
    "    # Updates generator gradients\n",
    "    gradients_gen = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gen_optimizer.apply_gradients(zip(gradients_gen, generator.trainable_variables))\n",
    "    \n",
    "    # Returns the sum of discriminator loss with fake and real images\n",
    "    return disc_lossReal + disc_lossFake, gen_loss\n",
    "\n",
    "# Creates a seed to always generate the same images and thus compare the network's evolution\n",
    "tf.random.set_seed(347)\n",
    "seed = tf.random.normal([25, latent_dim])\n",
    "\n",
    "# Network training function\n",
    "def train(dataset, epochs):\n",
    "    # Generates images before training starts\n",
    "    generate_and_save_images(generated_images_folder, generator, 0, seed)\n",
    "    # Saves the discriminator and generator at epoch 0\n",
    "    discriminator.save(trained_models_folder + \"Discriminator_epoch_0\")\n",
    "    generator.save(trained_models_folder + \"Generator_epoch_0\")\n",
    "    for epoch in range(epochs):\n",
    "        print('Current training epoch {} (out of {}).'.format(epoch+1, epochs))\n",
    "        # Loop that iterates over the dataset to train the network\n",
    "        for image_batch in tqdm(dataset):\n",
    "            disc_loss, gen_loss = train_step(image_batch)\n",
    "        # Generates and saves fake images as the network evolves\n",
    "        generated_images=generate_and_save_images(generated_images_folder, generator, epoch+1, seed)\n",
    "        fig=image_grid(generated_images)\n",
    "        with tensorboard.as_default():\n",
    "            # Logs generator and discriminator loss and generated images to Tensorboard\n",
    "            tf.summary.scalar('Loss discriminator', disc_loss.numpy(), step=epoch)\n",
    "            tf.summary.scalar('Loss generator', gen_loss.numpy(), step=epoch)\n",
    "            tf.summary.image('Generated images', plot_to_image(fig), step=epoch)\n",
    "\n",
    "        # If the current epoch is a multiple of 10, save the generator and discriminator\n",
    "        if epoch % 10 == 0:\n",
    "            discriminator.save(trained_models_folder + \"Discriminator_epoch_%d\" % epoch)\n",
    "            generator.save(trained_models_folder + \"Generator_epoch_%d\" % epoch)\n",
    "\n",
    "    # In the last iteration, save the generator and discriminator and the last images produced by the generator\n",
    "    generate_and_save_images(generated_images_folder, generator, epochs, seed)\n",
    "    discriminator.save(trained_models_folder + \"Discriminator_epoch_%d\" % epochs)\n",
    "    generator.save(trained_models_folder + \"Generator_epoch_%d\" % epochs)\n",
    "\n",
    "# Calls the train function to start training\n",
    "train(dataset, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f567df1c",
   "metadata": {},
   "source": [
    "## Cargar los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f6447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the folder from which the trained models will be loaded\n",
    "epoch = 0 # Specify the epoch of the model to load\n",
    "generator = tf.keras.models.load_model(trained_models_folder + \"Generator_epoch_%d\" % epoch)\n",
    "discriminator = tf.keras.models.load_model(trained_models_folder + \"Discriminator_epoch_%d\" % epoch)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
