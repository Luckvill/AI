import torch
import torch.optim as optim
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import torchvision.datasets as datasets
from torch.utils.tensorboard import SummaryWriter
import torchvision
from model import Discriminator, Generator
from math import log2
from tqdm import tqdm
from torchvision.utils import save_image
torch.backends.cudnn.benchmarks = True

# Set the initial resolution to start training the proGAN
initialResolution = 4

# Specify the directory where the images for training the network are located
directory = '' # Format: '{dataset_directory}'

# Specify the folder where the trained model will be saved (if the folder is different from the current one, add "\ " at the end)
trained_models_folder=""  # Format: "{models_save_directory}\ "

# Specify the format in which the models will be saved
saveGenerator = trained_models_folder + "generator.pth"
saveDiscriminator = trained_models_folder + "discriminator.pth"

# Specify the folder where the images generated by the model will be saved
generated_images_folder=''  # Format: '{generated_images_directory}'

# Specify whether to load an existing model
loadModel=False

# Specify to use GPU if available
device = "cuda" if torch.cuda.is_available() else "cpu"

# Specify the batch size for different resolutions
batchSize = [16, 65, 48, 32, 16, 16]

# Specify the dimension of the latent space
latent_dim = 256

# Set the lambda value for WGAN-GP
LAMBDA_GP = 10

# Specify the number of training epochs per resolution
numEpochs = [35] * len(batchSize)

# Create a seed to always generate the same images and thus compare the network's evolution
noise = torch.randn(25, latent_dim, 1, 1).to(device)


# Load the car dataset, normalize, resize, and horizontally flip its images
def get_loader(image_size):
    transform = transforms.Compose(
        [
            transforms.Resize((image_size, image_size)),
            transforms.ToTensor(),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.Normalize(
                [0.5 for _ in range(3)],
                [0.5 for _ in range(3)],
            ),
        ]
    )
    batch_size = batchSize[int(log2(image_size / 4))]
    dataset = datasets.ImageFolder(root=directory, transform=transform)
    loader = DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=8,
        pin_memory=True,
    )
    return loader, dataset

# Gradient penalty function
def gradient_penalty(discriminator, real, fake, alpha, train_step, device="cpu"):
    # Create the beta vector for the penalty
    beta = torch.rand((real.shape[0], 1, 1, 1)).repeat(1, real.shape[1], real.shape[2], real.shape[3]).to(device)
    # Interpolate the fake (generated) images with the real ones
    interpolated_images = real * beta + fake.detach() * (1 - beta)
    interpolated_images.requires_grad_(True)

    # The discriminator makes predictions on the interpolated images
    mixed_scores = discriminator(interpolated_images, alpha, train_step)

    # Calculate the gradient of the discriminator
    gradient = torch.autograd.grad(
        inputs=interpolated_images,
        outputs=mixed_scores,
        grad_outputs=torch.ones_like(mixed_scores),
        create_graph=True,
        retain_graph=True,
    )[0]
    gradient = gradient.view(gradient.shape[0], -1)
    # Normalize the calculated gradient
    gradientNorm = gradient.norm(2, dim=1)
    # Calculate the gradient penalty
    gradient_penalty = torch.mean((gradientNorm - 1) ** 2)
    return gradient_penalty


# Print to Tensorboard the discriminator loss, generator loss, and images generated by the network
def plot_to_tensorboard(tensorboard, disc_loss, gen_loss, fake, tensorboard_step):
    tensorboard.add_scalar("Loss discriminator", disc_loss, global_step=tensorboard_step)
    tensorboard.add_scalar("Loss generator", gen_loss, global_step=tensorboard_step)
    with torch.no_grad():
        img_grid_fake = torchvision.utils.make_grid(fake[:25], nrow=5, normalize=True)
        tensorboard.add_image("Fake", img_grid_fake, global_step=tensorboard_step)
    save_image(img_grid_fake, f"{generated_images_folder}/img_{tensorboard_step}.png")

# Save the model
def save_checkpoint(model, optimizer, filename="my_checkpoint.pth.tar"):
    checkpoint = {
        "state_dict": model.state_dict(),
        "optimizer": optimizer.state_dict(),
    }
    torch.save(checkpoint, filename)
    print("Models saved successfully")

# Load the model
def load_checkpoint(checkpoint_file, model, optimizer, lr):
    checkpoint = torch.load(checkpoint_file, map_location="cuda")
    model.load_state_dict(checkpoint["state_dict"])
    optimizer.load_state_dict(checkpoint["optimizer"])
    for param_group in optimizer.param_groups:
        param_group["lr"] = lr
    print("Models loaded successfully")

# Network training function
def train_step(
    discriminator,
    generator,
    tensorboard_step,
    loader,
    dataset,
    step,
    alpha,
    opt_discriminator,
    opt_generator,
    tensorboard,
    scaler_generator,
    scaler_discriminator,
):
    loop = tqdm(loader, leave=True)
    # Loop that iterates over the dataset to train the network
    for batch_idx, (real, _) in enumerate(loop):
        real = real.to(device)
        curRes = real.shape[0]

        # Generate a vector of random images (noise)
        noise = torch.randn(curRes, latent_dim, 1, 1).to(device)

        # Discriminator training
        with torch.cuda.amp.autocast():
            # Generate fake images with the generator
            generated_images = generator(noise, alpha, step)
            # Create discriminator predictions for real images
            real_preds = discriminator(real, alpha, step)
            # Create discriminator predictions for fake images
            fake_preds = discriminator(generated_images.detach(), alpha, step)
            # Calculate the gradient penalty
            gp = gradient_penalty(discriminator, real, generated_images, alpha, step, device=device)
            # Calculate the discriminator loss
            disc_loss =-(torch.mean(real_preds) - torch.mean(fake_preds))+ LAMBDA_GP * gp + (0.001 * torch.mean(real_preds ** 2))

        # Update discriminator gradients
        opt_discriminator.zero_grad()
        scaler_discriminator.scale(disc_loss).backward()
        scaler_discriminator.step(opt_discriminator)
        scaler_discriminator.update()

        # Generator training
        with torch.cuda.amp.autocast():
            # Create discriminator predictions for fake images
            fake_preds = discriminator(generated_images, alpha, step)
            # Calculate the generator loss
            gen_loss = -torch.mean(fake_preds)

        # Update generator gradients
        opt_generator.zero_grad()
        scaler_generator.scale(gen_loss).backward()
        scaler_generator.step(opt_generator)
        scaler_generator.update()

        # Update the alpha parameter
        alpha += curRes / ((numEpochs[step] * 0.5) * len(dataset))
        # Ensure alpha is not greater than one
        alpha = min(alpha, 1)

        # Print to console the gradient penalty, generator loss, and discriminator loss
        loop.set_postfix(gp=gp.item(),gen_loss=gen_loss.item(), disc_loss=disc_loss.item())

    # Update Tensorboard
    with torch.no_grad():
        fakes = generator(noise, alpha, step) * 0.5 + 0.5
    plot_to_tensorboard(
        tensorboard,
        disc_loss.item(),
        gen_loss.item(),
        fakes.detach(),
        tensorboard_step,
    )
    tensorboard_step += 1
    return tensorboard_step, disc_loss,gen_loss, alpha

# Network training function
def train():
    # Create the two models: generator and discriminator
    generator = Generator(latent_dim, img_channels=3).to(device)
    discriminator = Discriminator(latent_dim, img_channels=3).to(device)

    # Initialize the optimizers for the generator and discriminator
    opt_generator = optim.Adam(generator.parameters(), lr=1e-3, betas=(0.0, 0.99))
    opt_discriminator = optim.Adam(discriminator.parameters(), lr=1e-3, betas=(0.0, 0.99))

    # Initialize the gradient scalers for the generator and discriminator
    scaler_generator = torch.cuda.amp.GradScaler()
    scaler_discriminator = torch.cuda.amp.GradScaler()

    # Create the Tensorboard writer
    tensorboard = SummaryWriter(f"logs2")

    # Check if models should be loaded
    if loadModel:
        load_checkpoint(saveGenerator, generator, opt_generator, 1e-3,)
        load_checkpoint(saveDiscriminator, discriminator, opt_discriminator, 1e-3,)

    tensorboard_step = 0
    generator.train()
    discriminator.train()
    # Create the variable that indicates the current resolution
    step = int(log2(initialResolution / 4))
    for num_epochs in numEpochs[step:]:
        alpha = 1e-5  # start with very low alpha
        loader, dataset = get_loader(4 * 2 ** step)  # 4->0, 8->1, 16->2, 32->3, 64 -> 4
        print(f"Current image resolution: {4 * 2 ** step}")

        for epoch in range(num_epochs):
            print('Current training epoch {} (out of a total of {}).'.format(epoch + 1, num_epochs))

            tensorboard_step, disc_loss,gen_loss, alpha = train_step(
                discriminator,
                generator,
                tensorboard_step,
                loader,
                dataset,
                step,
                alpha,
                opt_discriminator,
                opt_generator,
                tensorboard,
                scaler_generator,
                scaler_discriminator,
            )
            # Save the models
            save_checkpoint(generator, opt_generator, filename=saveGenerator)
            save_checkpoint(discriminator, opt_discriminator, filename=saveDiscriminator)
        step += 1

if __name__ == "__main__":
    train()