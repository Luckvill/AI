{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d02150cc",
   "metadata": {},
   "source": [
    "## Funciones utilizadas para Differentiable Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bc095e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Functions for Differentiable Augmentation\n",
    "def DiffAugment(x, policy='', channels_first=False):\n",
    "    if policy:\n",
    "        if channels_first:\n",
    "            x = tf.transpose(x, [0, 2, 3, 1])\n",
    "        for p in policy.split(','):\n",
    "            for f in AUGMENT_FNS[p]:\n",
    "                x = f(x)\n",
    "        if channels_first:\n",
    "            x = tf.transpose(x, [0, 3, 1, 2])\n",
    "    return x\n",
    "\n",
    "# Function to randomly change image brightness\n",
    "def rand_brightness(x):\n",
    "    magnitude = tf.random.uniform([tf.shape(x)[0], 1, 1, 1]) - 0.5\n",
    "    x = x + magnitude\n",
    "    return x\n",
    "\n",
    "# Function to randomly change image saturation\n",
    "def rand_saturation(x):\n",
    "    magnitude = tf.random.uniform([tf.shape(x)[0], 1, 1, 1]) * 2\n",
    "    x_mean = tf.reduce_mean(x, axis=3, keepdims=True)\n",
    "    x = (x - x_mean) * magnitude + x_mean\n",
    "    return x\n",
    "\n",
    "# Function to randomly change image contrast\n",
    "def rand_contrast(x):\n",
    "    magnitude = tf.random.uniform([tf.shape(x)[0], 1, 1, 1]) + 0.5\n",
    "    x_mean = tf.reduce_mean(x, axis=[1, 2, 3], keepdims=True)\n",
    "    x = (x - x_mean) * magnitude + x_mean\n",
    "    return x\n",
    "\n",
    "# Function to randomly translate images\n",
    "def rand_translation(x, ratio=0.125):\n",
    "    batch_size = tf.shape(x)[0]\n",
    "    image_size = tf.shape(x)[1:3]\n",
    "    shift = tf.cast(tf.cast(image_size, tf.float32) * ratio + 0.5, tf.int32)\n",
    "    translation_x = tf.random.uniform([batch_size, 1], -shift[0], shift[0] + 1, dtype=tf.int32)\n",
    "    translation_y = tf.random.uniform([batch_size, 1], -shift[1], shift[1] + 1, dtype=tf.int32)\n",
    "    grid_x = tf.clip_by_value(tf.expand_dims(tf.range(image_size[0], dtype=tf.int32), 0) + translation_x + 1, 0, image_size[0] + 1)\n",
    "    grid_y = tf.clip_by_value(tf.expand_dims(tf.range(image_size[1], dtype=tf.int32), 0) + translation_y + 1, 0, image_size[1] + 1)\n",
    "    x = tf.gather_nd(tf.pad(x, [[0, 0], [1, 1], [0, 0], [0, 0]]), tf.expand_dims(grid_x, -1), batch_dims=1)\n",
    "    x = tf.transpose(tf.gather_nd(tf.pad(tf.transpose(x, [0, 2, 1, 3]), [[0, 0], [1, 1], [0, 0], [0, 0]]), tf.expand_dims(grid_y, -1), batch_dims=1), [0, 2, 1, 3])\n",
    "    return x\n",
    "\n",
    "# Function to randomly cutout images\n",
    "def rand_cutout(x, ratio=0.5):\n",
    "    batch_size = tf.shape(x)[0]\n",
    "    image_size = tf.shape(x)[1:3]\n",
    "    cutout_size = tf.cast(tf.cast(image_size, tf.float32) * ratio + 0.5, tf.int32)\n",
    "    offset_x = tf.random.uniform([tf.shape(x)[0], 1, 1], maxval=image_size[0] + (1 - cutout_size[0] % 2), dtype=tf.int32)\n",
    "    offset_y = tf.random.uniform([tf.shape(x)[0], 1, 1], maxval=image_size[1] + (1 - cutout_size[1] % 2), dtype=tf.int32)\n",
    "    grid_batch, grid_x, grid_y = tf.meshgrid(tf.range(batch_size, dtype=tf.int32), tf.range(cutout_size[0], dtype=tf.int32), tf.range(cutout_size[1], dtype=tf.int32), indexing='ij')\n",
    "    cutout_grid = tf.stack([grid_batch, grid_x + offset_x - cutout_size[0] // 2, grid_y + offset_y - cutout_size[1] // 2], axis=-1)\n",
    "    mask_shape = tf.stack([batch_size, image_size[0], image_size[1]])\n",
    "    cutout_grid = tf.maximum(cutout_grid, 0)\n",
    "    cutout_grid = tf.minimum(cutout_grid, tf.reshape(mask_shape - 1, [1, 1, 1, 3]))\n",
    "    mask = tf.maximum(1 - tf.scatter_nd(cutout_grid, tf.ones([batch_size, cutout_size[0], cutout_size[1]], dtype=tf.float32), mask_shape), 0)\n",
    "    x = x * tf.expand_dims(mask, axis=3)\n",
    "    return x\n",
    "\n",
    "AUGMENT_FNS = {\n",
    "    'color': [rand_brightness, rand_saturation, rand_contrast],\n",
    "    'translation': [rand_translation],\n",
    "    'cutout': [rand_cutout],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c86f47c",
   "metadata": {},
   "source": [
    "## Ejecutar los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ce2f38",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import Input, Dense, Flatten, Reshape\n",
    "from tensorflow.keras import preprocessing, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import time\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Tensorboard writer is created\n",
    "tensorboard= tf.summary.create_file_writer(logdir='logs/{}'.format(\"Cars{}\".format(int(time.time()))))\n",
    "\n",
    "# Directory where the images for training the network are located\n",
    "directory=\"\" # Format: \"{directory}\"\n",
    "\n",
    "# Image size that the network will generate\n",
    "img_size = 128\n",
    "\n",
    "# Folder where the trained model will be saved\n",
    "trained_models_folder =\"\" # Format: \"{directory}\\ \"\n",
    "\n",
    "# Folder where the images generated by the model will be saved\n",
    "generated_images_folder=\"\" # Format: \"{directory}\\ \"\n",
    "\n",
    "# Batch size\n",
    "batch_size = 200\n",
    "\n",
    "# Latent space dimension\n",
    "latent_dim=100\n",
    "\n",
    "# Loads the car dataset, normalizes and resizes its images\n",
    "def get_loader(img_size):\n",
    "    def train_preprocessing(x):\n",
    "        x = tf.cast(x, tf.float32)\n",
    "        x = x / 255.0  # normalization\n",
    "        return x\n",
    "    dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        directory,\n",
    "        label_mode=None,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        seed=123,\n",
    "        image_size=(img_size, img_size),\n",
    "    )\n",
    "    datasetmapeado = dataset.map(lambda x: train_preprocessing(x))\n",
    "    return datasetmapeado\n",
    "\n",
    "dataset=get_loader(img_size)\n",
    "\n",
    "# Builds the generator\n",
    "def get_generator(latent_dim):\n",
    "    generator = Sequential(name='Generator')\n",
    "    generator.add(Input(shape=(latent_dim,)))\n",
    "    generator.add(Dense(100, activation=\"relu\", input_shape=(latent_dim,), kernel_initializer=\"he_normal\"))\n",
    "    generator.add(Dense(150, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
    "    generator.add(Dense(200, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
    "    generator.add(Dense(img_size*img_size*3, activation=\"tanh\"))\n",
    "    generator.add(Reshape((img_size, img_size, 3)))\n",
    "    return generator\n",
    "\n",
    "# Builds the discriminator\n",
    "def get_discriminator():\n",
    "    discriminator = Sequential(name='Discriminator')\n",
    "    discriminator.add(Input(shape=(128, 128, 3)))\n",
    "    discriminator.add(Flatten())\n",
    "    discriminator.add(Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
    "    discriminator.add(Dense(150, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
    "    discriminator.add(Dense(200, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
    "    discriminator.add(Dense(1, activation=\"sigmoid\"))\n",
    "    return discriminator\n",
    "\n",
    "# Variables to hold the generator and discriminator models\n",
    "generator=get_generator(latent_dim)\n",
    "discriminator=get_discriminator()\n",
    "\n",
    "# Objective function used\n",
    "binary_cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "# Generator loss function\n",
    "def generator_loss(label, fake_output):\n",
    "    gen_loss = binary_cross_entropy(label, fake_output)\n",
    "    return gen_loss\n",
    "\n",
    "# Discriminator loss function\n",
    "def discriminator_loss(label, output):\n",
    "    disc_loss = binary_cross_entropy(label, output)\n",
    "    return disc_loss\n",
    "\n",
    "# Initialize optimizers for generator and discriminator\n",
    "gen_optimizer = disc_optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "# Compile models specifying their optimizers and objective function (Binary Cross Entropy)\n",
    "generator.compile(gen_optimizer, loss=binary_cross_entropy)\n",
    "discriminator.compile(disc_optimizer, loss=binary_cross_entropy)\n",
    "\n",
    "# Print generator and discriminator summaries\n",
    "generator.summary()\n",
    "discriminator.summary()\n",
    "\n",
    "# Returns images in a format suitable for storing in Tensorboard\n",
    "def plot_to_image(figure):\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "# Creates a 5x5 grid with the received images\n",
    "def image_grid(images):\n",
    "    figure = plt.figure(figsize=(10,10))\n",
    "    for i in range(images.shape[0]):\n",
    "        img = preprocessing.image.array_to_img((images[i] + 1 / 2))\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(img)\n",
    "    return figure\n",
    "\n",
    "# Generates and saves images produced by the generator in a local folder\n",
    "def generate_and_save_images(folder, model, epoch, seed, dim=(5, 5), figsize=(5, 5)):\n",
    "    generated_images = model(seed)\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        img = preprocessing.image.array_to_img((generated_images[i] + 1 / 2))\n",
    "        plt.imshow(img)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(folder + 'generated_image_epoch_%d.png' % epoch)\n",
    "    plt.close()\n",
    "    return generated_images\n",
    "\n",
    "# Trains the network via train_step\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    # Generates a vector of random images (noise)\n",
    "    noise = tf.random.normal([batch_size, latent_dim])\n",
    "    \n",
    "    # Processes batch images with Differentiable Augmentation\n",
    "    images = DiffAugment(images, policy='color,translation,cutout')\n",
    "\n",
    "    # Trains the discriminator with real images\n",
    "    with tf.GradientTape() as disc_tapeReal:\n",
    "        # Discriminator predictions for real images\n",
    "        real_preds = discriminator(images, training=True)\n",
    "        # Vector of 1's multiplied by 0.9 to encourage learning, indicating real images\n",
    "        ones = tf.ones_like(real_preds) * 0.9\n",
    "        # Discriminator loss with real images\n",
    "        disc_lossReal = discriminator_loss(ones, real_preds)\n",
    "\n",
    "    # Update discriminator gradients\n",
    "    gradients_discReal = disc_tapeReal.gradient(disc_lossReal, discriminator.trainable_variables)\n",
    "    disc_optimizer.apply_gradients(zip(gradients_discReal, discriminator.trainable_variables))\n",
    "\n",
    "    # Trains the discriminator with fake images\n",
    "    with tf.GradientTape() as disc_tapeFake:\n",
    "        # Generates fake images with the generator\n",
    "        generated_images = generator(noise, training=True)\n",
    "        # Processes fake images with Differentiable Augmentation\n",
    "        generated_images = DiffAugment(generated_images, policy='color,translation,cutout')\n",
    "        # Discriminator predictions for fake images\n",
    "        fake_preds = discriminator(generated_images, training=True)\n",
    "        # Vector of 0's indicating fake images\n",
    "        ceros = tf.zeros_like(fake_preds)\n",
    "        # Discriminator loss with fake images\n",
    "        disc_lossFake = discriminator_loss(ceros, fake_preds)\n",
    "\n",
    "    # Update discriminator gradients\n",
    "    gradients_discFake = disc_tapeFake.gradient(disc_lossFake, discriminator.trainable_variables)\n",
    "    disc_optimizer.apply_gradients(zip(gradients_discFake, discriminator.trainable_variables))\n",
    "\n",
    "    # Trains the generator\n",
    "    with tf.GradientTape() as gen_tape:\n",
    "        # Generates fake images with the generator\n",
    "        generated_images = generator(noise, training=True)\n",
    "        # Processes fake images with Differentiable Augmentation\n",
    "        generated_images = DiffAugment(generated_images, policy='color,translation,cutout')\n",
    "        # Discriminator predictions for fake images\n",
    "        fake_preds = discriminator(generated_images, training=True)\n",
    "        # \"Tricks\" the discriminator with a vector of 1's so it thinks generated images are real and the generator learns\n",
    "        ones = tf.ones_like(fake_preds)\n",
    "        # Generator loss\n",
    "        gen_loss = generator_loss(ones, fake_preds)\n",
    "\n",
    "    # Update generator gradients\n",
    "    gradients_gen = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gen_optimizer.apply_gradients(zip(gradients_gen, generator.trainable_variables))\n",
    "    \n",
    "    # Returns the sum of the discriminator loss with fake and real images\n",
    "    return disc_lossReal + disc_lossFake, gen_loss\n",
    "\n",
    "# Creates a seed to always generate the same images and compare network evolution\n",
    "tf.random.set_seed(347)\n",
    "seed = tf.random.normal([25, latent_dim])\n",
    "\n",
    "# Network training function\n",
    "def train(dataset, epochs):\n",
    "    # Generates images before training starts\n",
    "    generate_and_save_images(generated_images_folder, generator, 0, seed)\n",
    "    # Saves discriminator and generator at epoch 0\n",
    "    discriminator.save(trained_models_folder + \"Discriminator_epoch_0\")\n",
    "    generator.save(trained_models_folder + \"Generator_epoch_0\")\n",
    "    for epoch in range(epochs):\n",
    "        print('Current training epoch {} (out of {}).'.format(epoch+1, epochs))\n",
    "        # Loop that iterates over the dataset to train the network\n",
    "        for image_batch in tqdm(dataset):\n",
    "            disc_loss, gen_loss = train_step(image_batch)\n",
    "        # Generates and saves fake images as the network evolves\n",
    "        generated_images=generate_and_save_images(generated_images_folder, generator, epoch+1, seed)\n",
    "        fig=image_grid(generated_images)\n",
    "        with tensorboard.as_default():\n",
    "            # Prints to Tensorboard the generator and discriminator loss and the images generated by the generator\n",
    "            tf.summary.scalar('Loss discriminator', disc_loss.numpy(), step=epoch)\n",
    "            tf.summary.scalar('Loss generator', gen_loss.numpy(), step=epoch)\n",
    "            tf.summary.image('Generated images', plot_to_image(fig), step=epoch)\n",
    "\n",
    "        # If the current epoch is a multiple of 10, save the generator and discriminator\n",
    "        if epoch % 10 == 0:\n",
    "            discriminator.save(trained_models_folder + \"Discriminator_epoch_%d\" % epoch)\n",
    "            generator.save(trained_models_folder + \"Generator_epoch_%d\" % epoch)\n",
    "\n",
    "    # In the last iteration, save the generator and discriminator and the last images produced by the generator\n",
    "    generate_and_save_images(generated_images_folder, generator, epochs, seed)\n",
    "    discriminator.save(trained_models_folder + \"Discriminator_epoch_%d\" % epochs)\n",
    "    generator.save(trained_models_folder + \"Generator_epoch_%d\" % epochs)\n",
    "\n",
    "# Calls the train function to start training\n",
    "train(dataset, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b312c811",
   "metadata": {},
   "source": [
    "## Cargar los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f6a79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the folder from which the trained models will be loaded\n",
    "epoch = 0  # Specify the epoch of the model you want to load\n",
    "generator = tf.keras.models.load_model(trained_models_folder + \"Generator_epoch_%d\" % epoch)\n",
    "discriminator = tf.keras.models.load_model(trained_models_folder + \"Discriminator_epoch_%d\" % epoch)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
